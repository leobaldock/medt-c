{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df4d6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.8.1\n",
      "\n",
      "Python 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(\"GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc3ea40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.8.1\n",
      "\n",
      "Python 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "GPU is available\n",
      "ResNetBasicBlock(\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Sequential(\n",
      "      (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (activate): ReLU(inplace=True)\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "ResNetBottleNeckBlock(\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2dAuto(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Sequential(\n",
      "      (0): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Sequential(\n",
      "      (0): Conv2dAuto(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (activate): ReLU(inplace=True)\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "        Conv2dAuto-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "        Conv2dAuto-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      " ResNetBasicBlock-11           [-1, 64, 56, 56]               0\n",
      "       Conv2dAuto-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "       Conv2dAuto-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      " ResNetBasicBlock-18           [-1, 64, 56, 56]               0\n",
      "      ResNetLayer-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-21          [-1, 128, 28, 28]             256\n",
      "       Conv2dAuto-22          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "             ReLU-24          [-1, 128, 28, 28]               0\n",
      "       Conv2dAuto-25          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-26          [-1, 128, 28, 28]             256\n",
      "             ReLU-27          [-1, 128, 28, 28]               0\n",
      " ResNetBasicBlock-28          [-1, 128, 28, 28]               0\n",
      "       Conv2dAuto-29          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
      "             ReLU-31          [-1, 128, 28, 28]               0\n",
      "       Conv2dAuto-32          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "             ReLU-34          [-1, 128, 28, 28]               0\n",
      " ResNetBasicBlock-35          [-1, 128, 28, 28]               0\n",
      "      ResNetLayer-36          [-1, 128, 28, 28]               0\n",
      "           Conv2d-37          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-38          [-1, 256, 14, 14]             512\n",
      "       Conv2dAuto-39          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-40          [-1, 256, 14, 14]             512\n",
      "             ReLU-41          [-1, 256, 14, 14]               0\n",
      "       Conv2dAuto-42          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-43          [-1, 256, 14, 14]             512\n",
      "             ReLU-44          [-1, 256, 14, 14]               0\n",
      " ResNetBasicBlock-45          [-1, 256, 14, 14]               0\n",
      "       Conv2dAuto-46          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-47          [-1, 256, 14, 14]             512\n",
      "             ReLU-48          [-1, 256, 14, 14]               0\n",
      "       Conv2dAuto-49          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-50          [-1, 256, 14, 14]             512\n",
      "             ReLU-51          [-1, 256, 14, 14]               0\n",
      " ResNetBasicBlock-52          [-1, 256, 14, 14]               0\n",
      "      ResNetLayer-53          [-1, 256, 14, 14]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "       Conv2dAuto-56            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       Conv2dAuto-59            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-60            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-61            [-1, 512, 7, 7]               0\n",
      " ResNetBasicBlock-62            [-1, 512, 7, 7]               0\n",
      "       Conv2dAuto-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       Conv2dAuto-66            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-67            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-68            [-1, 512, 7, 7]               0\n",
      " ResNetBasicBlock-69            [-1, 512, 7, 7]               0\n",
      "      ResNetLayer-70            [-1, 512, 7, 7]               0\n",
      "    ResNetEncoder-71            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-72            [-1, 512, 1, 1]               0\n",
      "           Linear-73                 [-1, 1000]         513,000\n",
      "    ResnetDecoder-74                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 65.86\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 111.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%run ResNet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9baf0e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.8.1\n",
      "\n",
      "Python 3.8.8 (default, Feb 24 2021, 21:46:12) \n",
      "[GCC 7.3.0]\n",
      "GPU is available\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedT_C(\n",
      "  (global_branch): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): Conv2d(3, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "      (1): GatedAxialTransformerLayer(\n",
      "        (conv_down): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (height_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (width_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (conv_up): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): GatedAxialTransformerLayer(\n",
      "        (conv_down): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (height_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (width_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (conv_up): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (local_branch): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): Conv2d(3, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "      (1): GatedAxialTransformerLayer(\n",
      "        (conv_down): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (height_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (width_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (conv_up): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): GatedAxialTransformerLayer(\n",
      "        (conv_down): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (height_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (width_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (conv_up): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): GatedAxialTransformerLayer(\n",
      "        (conv_down): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (height_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (width_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (conv_up): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): GatedAxialTransformerLayer(\n",
      "        (conv_down): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (height_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (width_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (conv_up): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): GatedAxialTransformerLayer(\n",
      "        (conv_down): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (height_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (width_attention): AxialAttention(\n",
      "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
      "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (conv_up): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (avg): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (decoder): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 256, 32, 32]          37,888\n",
      "            Conv2d-2          [-1, 128, 32, 32]          32,896\n",
      "       BatchNorm2d-3          [-1, 128, 32, 32]             256\n",
      "              ReLU-4          [-1, 128, 32, 32]               0\n",
      "            Linear-5            [-1, 32, 8, 16]             256\n",
      "            Linear-6            [-1, 32, 8, 16]             256\n",
      "            Linear-7            [-1, 32, 8, 16]             256\n",
      "            Linear-8          [-1, 32, 32, 128]          16,512\n",
      "    AxialAttention-9          [-1, 128, 32, 32]               0\n",
      "           Linear-10            [-1, 32, 8, 16]             256\n",
      "           Linear-11            [-1, 32, 8, 16]             256\n",
      "           Linear-12            [-1, 32, 8, 16]             256\n",
      "           Linear-13          [-1, 32, 32, 128]          16,512\n",
      "   AxialAttention-14          [-1, 128, 32, 32]               0\n",
      "             ReLU-15          [-1, 128, 32, 32]               0\n",
      "           Conv2d-16          [-1, 256, 32, 32]          33,024\n",
      "      BatchNorm2d-17          [-1, 256, 32, 32]             512\n",
      "             ReLU-18          [-1, 256, 32, 32]               0\n",
      "GatedAxialTransformerLayer-19          [-1, 256, 32, 32]               0\n",
      "           Conv2d-20          [-1, 128, 32, 32]          32,896\n",
      "      BatchNorm2d-21          [-1, 128, 32, 32]             256\n",
      "             ReLU-22          [-1, 128, 32, 32]               0\n",
      "           Linear-23            [-1, 32, 8, 16]             256\n",
      "           Linear-24            [-1, 32, 8, 16]             256\n",
      "           Linear-25            [-1, 32, 8, 16]             256\n",
      "           Linear-26          [-1, 32, 32, 128]          16,512\n",
      "   AxialAttention-27          [-1, 128, 32, 32]               0\n",
      "           Linear-28            [-1, 32, 8, 16]             256\n",
      "           Linear-29            [-1, 32, 8, 16]             256\n",
      "           Linear-30            [-1, 32, 8, 16]             256\n",
      "           Linear-31          [-1, 32, 32, 128]          16,512\n",
      "   AxialAttention-32          [-1, 128, 32, 32]               0\n",
      "             ReLU-33          [-1, 128, 32, 32]               0\n",
      "           Conv2d-34          [-1, 256, 32, 32]          33,024\n",
      "      BatchNorm2d-35          [-1, 256, 32, 32]             512\n",
      "             ReLU-36          [-1, 256, 32, 32]               0\n",
      "GatedAxialTransformerLayer-37          [-1, 256, 32, 32]               0\n",
      "          Encoder-38          [-1, 256, 32, 32]               0\n",
      "           Conv2d-39            [-1, 256, 8, 8]          37,888\n",
      "           Conv2d-40            [-1, 128, 8, 8]          32,896\n",
      "      BatchNorm2d-41            [-1, 128, 8, 8]             256\n",
      "             ReLU-42            [-1, 128, 8, 8]               0\n",
      "           Linear-43             [-1, 8, 8, 16]             256\n",
      "           Linear-44             [-1, 8, 8, 16]             256\n",
      "           Linear-45             [-1, 8, 8, 16]             256\n",
      "           Linear-46            [-1, 8, 8, 128]          16,512\n",
      "   AxialAttention-47            [-1, 128, 8, 8]               0\n",
      "           Linear-48             [-1, 8, 8, 16]             256\n",
      "           Linear-49             [-1, 8, 8, 16]             256\n",
      "           Linear-50             [-1, 8, 8, 16]             256\n",
      "           Linear-51            [-1, 8, 8, 128]          16,512\n",
      "   AxialAttention-52            [-1, 128, 8, 8]               0\n",
      "             ReLU-53            [-1, 128, 8, 8]               0\n",
      "           Conv2d-54            [-1, 256, 8, 8]          33,024\n",
      "      BatchNorm2d-55            [-1, 256, 8, 8]             512\n",
      "             ReLU-56            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-57            [-1, 256, 8, 8]               0\n",
      "           Conv2d-58            [-1, 128, 8, 8]          32,896\n",
      "      BatchNorm2d-59            [-1, 128, 8, 8]             256\n",
      "             ReLU-60            [-1, 128, 8, 8]               0\n",
      "           Linear-61             [-1, 8, 8, 16]             256\n",
      "           Linear-62             [-1, 8, 8, 16]             256\n",
      "           Linear-63             [-1, 8, 8, 16]             256\n",
      "           Linear-64            [-1, 8, 8, 128]          16,512\n",
      "   AxialAttention-65            [-1, 128, 8, 8]               0\n",
      "           Linear-66             [-1, 8, 8, 16]             256\n",
      "           Linear-67             [-1, 8, 8, 16]             256\n",
      "           Linear-68             [-1, 8, 8, 16]             256\n",
      "           Linear-69            [-1, 8, 8, 128]          16,512\n",
      "   AxialAttention-70            [-1, 128, 8, 8]               0\n",
      "             ReLU-71            [-1, 128, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]          33,024\n",
      "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
      "             ReLU-74            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-75            [-1, 256, 8, 8]               0\n",
      "           Conv2d-76            [-1, 128, 8, 8]          32,896\n",
      "      BatchNorm2d-77            [-1, 128, 8, 8]             256\n",
      "             ReLU-78            [-1, 128, 8, 8]               0\n",
      "           Linear-79             [-1, 8, 8, 16]             256\n",
      "           Linear-80             [-1, 8, 8, 16]             256\n",
      "           Linear-81             [-1, 8, 8, 16]             256\n",
      "           Linear-82            [-1, 8, 8, 128]          16,512\n",
      "   AxialAttention-83            [-1, 128, 8, 8]               0\n",
      "           Linear-84             [-1, 8, 8, 16]             256\n",
      "           Linear-85             [-1, 8, 8, 16]             256\n",
      "           Linear-86             [-1, 8, 8, 16]             256\n",
      "           Linear-87            [-1, 8, 8, 128]          16,512\n",
      "   AxialAttention-88            [-1, 128, 8, 8]               0\n",
      "             ReLU-89            [-1, 128, 8, 8]               0\n",
      "           Conv2d-90            [-1, 256, 8, 8]          33,024\n",
      "      BatchNorm2d-91            [-1, 256, 8, 8]             512\n",
      "             ReLU-92            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 128, 8, 8]          32,896\n",
      "      BatchNorm2d-95            [-1, 128, 8, 8]             256\n",
      "             ReLU-96            [-1, 128, 8, 8]               0\n",
      "           Linear-97             [-1, 8, 8, 16]             256\n",
      "           Linear-98             [-1, 8, 8, 16]             256\n",
      "           Linear-99             [-1, 8, 8, 16]             256\n",
      "          Linear-100            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-101            [-1, 128, 8, 8]               0\n",
      "          Linear-102             [-1, 8, 8, 16]             256\n",
      "          Linear-103             [-1, 8, 8, 16]             256\n",
      "          Linear-104             [-1, 8, 8, 16]             256\n",
      "          Linear-105            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-106            [-1, 128, 8, 8]               0\n",
      "            ReLU-107            [-1, 128, 8, 8]               0\n",
      "          Conv2d-108            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-109            [-1, 256, 8, 8]             512\n",
      "            ReLU-110            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-111            [-1, 256, 8, 8]               0\n",
      "          Conv2d-112            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-113            [-1, 128, 8, 8]             256\n",
      "            ReLU-114            [-1, 128, 8, 8]               0\n",
      "          Linear-115             [-1, 8, 8, 16]             256\n",
      "          Linear-116             [-1, 8, 8, 16]             256\n",
      "          Linear-117             [-1, 8, 8, 16]             256\n",
      "          Linear-118            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-119            [-1, 128, 8, 8]               0\n",
      "          Linear-120             [-1, 8, 8, 16]             256\n",
      "          Linear-121             [-1, 8, 8, 16]             256\n",
      "          Linear-122             [-1, 8, 8, 16]             256\n",
      "          Linear-123            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-124            [-1, 128, 8, 8]               0\n",
      "            ReLU-125            [-1, 128, 8, 8]               0\n",
      "          Conv2d-126            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-127            [-1, 256, 8, 8]             512\n",
      "            ReLU-128            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-129            [-1, 256, 8, 8]               0\n",
      "         Encoder-130            [-1, 256, 8, 8]               0\n",
      "          Conv2d-131            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-132            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-133            [-1, 128, 8, 8]             256\n",
      "            ReLU-134            [-1, 128, 8, 8]               0\n",
      "          Linear-135             [-1, 8, 8, 16]             256\n",
      "          Linear-136             [-1, 8, 8, 16]             256\n",
      "          Linear-137             [-1, 8, 8, 16]             256\n",
      "          Linear-138            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-139            [-1, 128, 8, 8]               0\n",
      "          Linear-140             [-1, 8, 8, 16]             256\n",
      "          Linear-141             [-1, 8, 8, 16]             256\n",
      "          Linear-142             [-1, 8, 8, 16]             256\n",
      "          Linear-143            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-144            [-1, 128, 8, 8]               0\n",
      "            ReLU-145            [-1, 128, 8, 8]               0\n",
      "          Conv2d-146            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-147            [-1, 256, 8, 8]             512\n",
      "            ReLU-148            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-149            [-1, 256, 8, 8]               0\n",
      "          Conv2d-150            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-151            [-1, 128, 8, 8]             256\n",
      "            ReLU-152            [-1, 128, 8, 8]               0\n",
      "          Linear-153             [-1, 8, 8, 16]             256\n",
      "          Linear-154             [-1, 8, 8, 16]             256\n",
      "          Linear-155             [-1, 8, 8, 16]             256\n",
      "          Linear-156            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-157            [-1, 128, 8, 8]               0\n",
      "          Linear-158             [-1, 8, 8, 16]             256\n",
      "          Linear-159             [-1, 8, 8, 16]             256\n",
      "          Linear-160             [-1, 8, 8, 16]             256\n",
      "          Linear-161            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-162            [-1, 128, 8, 8]               0\n",
      "            ReLU-163            [-1, 128, 8, 8]               0\n",
      "          Conv2d-164            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-165            [-1, 256, 8, 8]             512\n",
      "            ReLU-166            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-167            [-1, 256, 8, 8]               0\n",
      "          Conv2d-168            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-169            [-1, 128, 8, 8]             256\n",
      "            ReLU-170            [-1, 128, 8, 8]               0\n",
      "          Linear-171             [-1, 8, 8, 16]             256\n",
      "          Linear-172             [-1, 8, 8, 16]             256\n",
      "          Linear-173             [-1, 8, 8, 16]             256\n",
      "          Linear-174            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-175            [-1, 128, 8, 8]               0\n",
      "          Linear-176             [-1, 8, 8, 16]             256\n",
      "          Linear-177             [-1, 8, 8, 16]             256\n",
      "          Linear-178             [-1, 8, 8, 16]             256\n",
      "          Linear-179            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-180            [-1, 128, 8, 8]               0\n",
      "            ReLU-181            [-1, 128, 8, 8]               0\n",
      "          Conv2d-182            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-183            [-1, 256, 8, 8]             512\n",
      "            ReLU-184            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-185            [-1, 256, 8, 8]               0\n",
      "          Conv2d-186            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-187            [-1, 128, 8, 8]             256\n",
      "            ReLU-188            [-1, 128, 8, 8]               0\n",
      "          Linear-189             [-1, 8, 8, 16]             256\n",
      "          Linear-190             [-1, 8, 8, 16]             256\n",
      "          Linear-191             [-1, 8, 8, 16]             256\n",
      "          Linear-192            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-193            [-1, 128, 8, 8]               0\n",
      "          Linear-194             [-1, 8, 8, 16]             256\n",
      "          Linear-195             [-1, 8, 8, 16]             256\n",
      "          Linear-196             [-1, 8, 8, 16]             256\n",
      "          Linear-197            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-198            [-1, 128, 8, 8]               0\n",
      "            ReLU-199            [-1, 128, 8, 8]               0\n",
      "          Conv2d-200            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-201            [-1, 256, 8, 8]             512\n",
      "            ReLU-202            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-203            [-1, 256, 8, 8]               0\n",
      "          Conv2d-204            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-205            [-1, 128, 8, 8]             256\n",
      "            ReLU-206            [-1, 128, 8, 8]               0\n",
      "          Linear-207             [-1, 8, 8, 16]             256\n",
      "          Linear-208             [-1, 8, 8, 16]             256\n",
      "          Linear-209             [-1, 8, 8, 16]             256\n",
      "          Linear-210            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-211            [-1, 128, 8, 8]               0\n",
      "          Linear-212             [-1, 8, 8, 16]             256\n",
      "          Linear-213             [-1, 8, 8, 16]             256\n",
      "          Linear-214             [-1, 8, 8, 16]             256\n",
      "          Linear-215            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-216            [-1, 128, 8, 8]               0\n",
      "            ReLU-217            [-1, 128, 8, 8]               0\n",
      "          Conv2d-218            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-219            [-1, 256, 8, 8]             512\n",
      "            ReLU-220            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-221            [-1, 256, 8, 8]               0\n",
      "         Encoder-222            [-1, 256, 8, 8]               0\n",
      "          Conv2d-223            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-224            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-225            [-1, 128, 8, 8]             256\n",
      "            ReLU-226            [-1, 128, 8, 8]               0\n",
      "          Linear-227             [-1, 8, 8, 16]             256\n",
      "          Linear-228             [-1, 8, 8, 16]             256\n",
      "          Linear-229             [-1, 8, 8, 16]             256\n",
      "          Linear-230            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-231            [-1, 128, 8, 8]               0\n",
      "          Linear-232             [-1, 8, 8, 16]             256\n",
      "          Linear-233             [-1, 8, 8, 16]             256\n",
      "          Linear-234             [-1, 8, 8, 16]             256\n",
      "          Linear-235            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-236            [-1, 128, 8, 8]               0\n",
      "            ReLU-237            [-1, 128, 8, 8]               0\n",
      "          Conv2d-238            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-239            [-1, 256, 8, 8]             512\n",
      "            ReLU-240            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-241            [-1, 256, 8, 8]               0\n",
      "          Conv2d-242            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-243            [-1, 128, 8, 8]             256\n",
      "            ReLU-244            [-1, 128, 8, 8]               0\n",
      "          Linear-245             [-1, 8, 8, 16]             256\n",
      "          Linear-246             [-1, 8, 8, 16]             256\n",
      "          Linear-247             [-1, 8, 8, 16]             256\n",
      "          Linear-248            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-249            [-1, 128, 8, 8]               0\n",
      "          Linear-250             [-1, 8, 8, 16]             256\n",
      "          Linear-251             [-1, 8, 8, 16]             256\n",
      "          Linear-252             [-1, 8, 8, 16]             256\n",
      "          Linear-253            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-254            [-1, 128, 8, 8]               0\n",
      "            ReLU-255            [-1, 128, 8, 8]               0\n",
      "          Conv2d-256            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-257            [-1, 256, 8, 8]             512\n",
      "            ReLU-258            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-259            [-1, 256, 8, 8]               0\n",
      "          Conv2d-260            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-261            [-1, 128, 8, 8]             256\n",
      "            ReLU-262            [-1, 128, 8, 8]               0\n",
      "          Linear-263             [-1, 8, 8, 16]             256\n",
      "          Linear-264             [-1, 8, 8, 16]             256\n",
      "          Linear-265             [-1, 8, 8, 16]             256\n",
      "          Linear-266            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-267            [-1, 128, 8, 8]               0\n",
      "          Linear-268             [-1, 8, 8, 16]             256\n",
      "          Linear-269             [-1, 8, 8, 16]             256\n",
      "          Linear-270             [-1, 8, 8, 16]             256\n",
      "          Linear-271            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-272            [-1, 128, 8, 8]               0\n",
      "            ReLU-273            [-1, 128, 8, 8]               0\n",
      "          Conv2d-274            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-275            [-1, 256, 8, 8]             512\n",
      "            ReLU-276            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-277            [-1, 256, 8, 8]               0\n",
      "          Conv2d-278            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-279            [-1, 128, 8, 8]             256\n",
      "            ReLU-280            [-1, 128, 8, 8]               0\n",
      "          Linear-281             [-1, 8, 8, 16]             256\n",
      "          Linear-282             [-1, 8, 8, 16]             256\n",
      "          Linear-283             [-1, 8, 8, 16]             256\n",
      "          Linear-284            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-285            [-1, 128, 8, 8]               0\n",
      "          Linear-286             [-1, 8, 8, 16]             256\n",
      "          Linear-287             [-1, 8, 8, 16]             256\n",
      "          Linear-288             [-1, 8, 8, 16]             256\n",
      "          Linear-289            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-290            [-1, 128, 8, 8]               0\n",
      "            ReLU-291            [-1, 128, 8, 8]               0\n",
      "          Conv2d-292            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-293            [-1, 256, 8, 8]             512\n",
      "            ReLU-294            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-295            [-1, 256, 8, 8]               0\n",
      "          Conv2d-296            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-297            [-1, 128, 8, 8]             256\n",
      "            ReLU-298            [-1, 128, 8, 8]               0\n",
      "          Linear-299             [-1, 8, 8, 16]             256\n",
      "          Linear-300             [-1, 8, 8, 16]             256\n",
      "          Linear-301             [-1, 8, 8, 16]             256\n",
      "          Linear-302            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-303            [-1, 128, 8, 8]               0\n",
      "          Linear-304             [-1, 8, 8, 16]             256\n",
      "          Linear-305             [-1, 8, 8, 16]             256\n",
      "          Linear-306             [-1, 8, 8, 16]             256\n",
      "          Linear-307            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-308            [-1, 128, 8, 8]               0\n",
      "            ReLU-309            [-1, 128, 8, 8]               0\n",
      "          Conv2d-310            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-311            [-1, 256, 8, 8]             512\n",
      "            ReLU-312            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-313            [-1, 256, 8, 8]               0\n",
      "         Encoder-314            [-1, 256, 8, 8]               0\n",
      "          Conv2d-315            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-316            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-317            [-1, 128, 8, 8]             256\n",
      "            ReLU-318            [-1, 128, 8, 8]               0\n",
      "          Linear-319             [-1, 8, 8, 16]             256\n",
      "          Linear-320             [-1, 8, 8, 16]             256\n",
      "          Linear-321             [-1, 8, 8, 16]             256\n",
      "          Linear-322            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-323            [-1, 128, 8, 8]               0\n",
      "          Linear-324             [-1, 8, 8, 16]             256\n",
      "          Linear-325             [-1, 8, 8, 16]             256\n",
      "          Linear-326             [-1, 8, 8, 16]             256\n",
      "          Linear-327            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-328            [-1, 128, 8, 8]               0\n",
      "            ReLU-329            [-1, 128, 8, 8]               0\n",
      "          Conv2d-330            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-331            [-1, 256, 8, 8]             512\n",
      "            ReLU-332            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-333            [-1, 256, 8, 8]               0\n",
      "          Conv2d-334            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-335            [-1, 128, 8, 8]             256\n",
      "            ReLU-336            [-1, 128, 8, 8]               0\n",
      "          Linear-337             [-1, 8, 8, 16]             256\n",
      "          Linear-338             [-1, 8, 8, 16]             256\n",
      "          Linear-339             [-1, 8, 8, 16]             256\n",
      "          Linear-340            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-341            [-1, 128, 8, 8]               0\n",
      "          Linear-342             [-1, 8, 8, 16]             256\n",
      "          Linear-343             [-1, 8, 8, 16]             256\n",
      "          Linear-344             [-1, 8, 8, 16]             256\n",
      "          Linear-345            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-346            [-1, 128, 8, 8]               0\n",
      "            ReLU-347            [-1, 128, 8, 8]               0\n",
      "          Conv2d-348            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-349            [-1, 256, 8, 8]             512\n",
      "            ReLU-350            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-351            [-1, 256, 8, 8]               0\n",
      "          Conv2d-352            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-353            [-1, 128, 8, 8]             256\n",
      "            ReLU-354            [-1, 128, 8, 8]               0\n",
      "          Linear-355             [-1, 8, 8, 16]             256\n",
      "          Linear-356             [-1, 8, 8, 16]             256\n",
      "          Linear-357             [-1, 8, 8, 16]             256\n",
      "          Linear-358            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-359            [-1, 128, 8, 8]               0\n",
      "          Linear-360             [-1, 8, 8, 16]             256\n",
      "          Linear-361             [-1, 8, 8, 16]             256\n",
      "          Linear-362             [-1, 8, 8, 16]             256\n",
      "          Linear-363            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-364            [-1, 128, 8, 8]               0\n",
      "            ReLU-365            [-1, 128, 8, 8]               0\n",
      "          Conv2d-366            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-367            [-1, 256, 8, 8]             512\n",
      "            ReLU-368            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-369            [-1, 256, 8, 8]               0\n",
      "          Conv2d-370            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-371            [-1, 128, 8, 8]             256\n",
      "            ReLU-372            [-1, 128, 8, 8]               0\n",
      "          Linear-373             [-1, 8, 8, 16]             256\n",
      "          Linear-374             [-1, 8, 8, 16]             256\n",
      "          Linear-375             [-1, 8, 8, 16]             256\n",
      "          Linear-376            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-377            [-1, 128, 8, 8]               0\n",
      "          Linear-378             [-1, 8, 8, 16]             256\n",
      "          Linear-379             [-1, 8, 8, 16]             256\n",
      "          Linear-380             [-1, 8, 8, 16]             256\n",
      "          Linear-381            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-382            [-1, 128, 8, 8]               0\n",
      "            ReLU-383            [-1, 128, 8, 8]               0\n",
      "          Conv2d-384            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-385            [-1, 256, 8, 8]             512\n",
      "            ReLU-386            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-387            [-1, 256, 8, 8]               0\n",
      "          Conv2d-388            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-389            [-1, 128, 8, 8]             256\n",
      "            ReLU-390            [-1, 128, 8, 8]               0\n",
      "          Linear-391             [-1, 8, 8, 16]             256\n",
      "          Linear-392             [-1, 8, 8, 16]             256\n",
      "          Linear-393             [-1, 8, 8, 16]             256\n",
      "          Linear-394            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-395            [-1, 128, 8, 8]               0\n",
      "          Linear-396             [-1, 8, 8, 16]             256\n",
      "          Linear-397             [-1, 8, 8, 16]             256\n",
      "          Linear-398             [-1, 8, 8, 16]             256\n",
      "          Linear-399            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-400            [-1, 128, 8, 8]               0\n",
      "            ReLU-401            [-1, 128, 8, 8]               0\n",
      "          Conv2d-402            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-403            [-1, 256, 8, 8]             512\n",
      "            ReLU-404            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-405            [-1, 256, 8, 8]               0\n",
      "         Encoder-406            [-1, 256, 8, 8]               0\n",
      "          Conv2d-407            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-408            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-409            [-1, 128, 8, 8]             256\n",
      "            ReLU-410            [-1, 128, 8, 8]               0\n",
      "          Linear-411             [-1, 8, 8, 16]             256\n",
      "          Linear-412             [-1, 8, 8, 16]             256\n",
      "          Linear-413             [-1, 8, 8, 16]             256\n",
      "          Linear-414            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-415            [-1, 128, 8, 8]               0\n",
      "          Linear-416             [-1, 8, 8, 16]             256\n",
      "          Linear-417             [-1, 8, 8, 16]             256\n",
      "          Linear-418             [-1, 8, 8, 16]             256\n",
      "          Linear-419            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-420            [-1, 128, 8, 8]               0\n",
      "            ReLU-421            [-1, 128, 8, 8]               0\n",
      "          Conv2d-422            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-423            [-1, 256, 8, 8]             512\n",
      "            ReLU-424            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-425            [-1, 256, 8, 8]               0\n",
      "          Conv2d-426            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-427            [-1, 128, 8, 8]             256\n",
      "            ReLU-428            [-1, 128, 8, 8]               0\n",
      "          Linear-429             [-1, 8, 8, 16]             256\n",
      "          Linear-430             [-1, 8, 8, 16]             256\n",
      "          Linear-431             [-1, 8, 8, 16]             256\n",
      "          Linear-432            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-433            [-1, 128, 8, 8]               0\n",
      "          Linear-434             [-1, 8, 8, 16]             256\n",
      "          Linear-435             [-1, 8, 8, 16]             256\n",
      "          Linear-436             [-1, 8, 8, 16]             256\n",
      "          Linear-437            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-438            [-1, 128, 8, 8]               0\n",
      "            ReLU-439            [-1, 128, 8, 8]               0\n",
      "          Conv2d-440            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-441            [-1, 256, 8, 8]             512\n",
      "            ReLU-442            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-443            [-1, 256, 8, 8]               0\n",
      "          Conv2d-444            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-445            [-1, 128, 8, 8]             256\n",
      "            ReLU-446            [-1, 128, 8, 8]               0\n",
      "          Linear-447             [-1, 8, 8, 16]             256\n",
      "          Linear-448             [-1, 8, 8, 16]             256\n",
      "          Linear-449             [-1, 8, 8, 16]             256\n",
      "          Linear-450            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-451            [-1, 128, 8, 8]               0\n",
      "          Linear-452             [-1, 8, 8, 16]             256\n",
      "          Linear-453             [-1, 8, 8, 16]             256\n",
      "          Linear-454             [-1, 8, 8, 16]             256\n",
      "          Linear-455            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-456            [-1, 128, 8, 8]               0\n",
      "            ReLU-457            [-1, 128, 8, 8]               0\n",
      "          Conv2d-458            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-459            [-1, 256, 8, 8]             512\n",
      "            ReLU-460            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-461            [-1, 256, 8, 8]               0\n",
      "          Conv2d-462            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-463            [-1, 128, 8, 8]             256\n",
      "            ReLU-464            [-1, 128, 8, 8]               0\n",
      "          Linear-465             [-1, 8, 8, 16]             256\n",
      "          Linear-466             [-1, 8, 8, 16]             256\n",
      "          Linear-467             [-1, 8, 8, 16]             256\n",
      "          Linear-468            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-469            [-1, 128, 8, 8]               0\n",
      "          Linear-470             [-1, 8, 8, 16]             256\n",
      "          Linear-471             [-1, 8, 8, 16]             256\n",
      "          Linear-472             [-1, 8, 8, 16]             256\n",
      "          Linear-473            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-474            [-1, 128, 8, 8]               0\n",
      "            ReLU-475            [-1, 128, 8, 8]               0\n",
      "          Conv2d-476            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-477            [-1, 256, 8, 8]             512\n",
      "            ReLU-478            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-479            [-1, 256, 8, 8]               0\n",
      "          Conv2d-480            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-481            [-1, 128, 8, 8]             256\n",
      "            ReLU-482            [-1, 128, 8, 8]               0\n",
      "          Linear-483             [-1, 8, 8, 16]             256\n",
      "          Linear-484             [-1, 8, 8, 16]             256\n",
      "          Linear-485             [-1, 8, 8, 16]             256\n",
      "          Linear-486            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-487            [-1, 128, 8, 8]               0\n",
      "          Linear-488             [-1, 8, 8, 16]             256\n",
      "          Linear-489             [-1, 8, 8, 16]             256\n",
      "          Linear-490             [-1, 8, 8, 16]             256\n",
      "          Linear-491            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-492            [-1, 128, 8, 8]               0\n",
      "            ReLU-493            [-1, 128, 8, 8]               0\n",
      "          Conv2d-494            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-495            [-1, 256, 8, 8]             512\n",
      "            ReLU-496            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-497            [-1, 256, 8, 8]               0\n",
      "         Encoder-498            [-1, 256, 8, 8]               0\n",
      "          Conv2d-499            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-500            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-501            [-1, 128, 8, 8]             256\n",
      "            ReLU-502            [-1, 128, 8, 8]               0\n",
      "          Linear-503             [-1, 8, 8, 16]             256\n",
      "          Linear-504             [-1, 8, 8, 16]             256\n",
      "          Linear-505             [-1, 8, 8, 16]             256\n",
      "          Linear-506            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-507            [-1, 128, 8, 8]               0\n",
      "          Linear-508             [-1, 8, 8, 16]             256\n",
      "          Linear-509             [-1, 8, 8, 16]             256\n",
      "          Linear-510             [-1, 8, 8, 16]             256\n",
      "          Linear-511            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-512            [-1, 128, 8, 8]               0\n",
      "            ReLU-513            [-1, 128, 8, 8]               0\n",
      "          Conv2d-514            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-515            [-1, 256, 8, 8]             512\n",
      "            ReLU-516            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-517            [-1, 256, 8, 8]               0\n",
      "          Conv2d-518            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-519            [-1, 128, 8, 8]             256\n",
      "            ReLU-520            [-1, 128, 8, 8]               0\n",
      "          Linear-521             [-1, 8, 8, 16]             256\n",
      "          Linear-522             [-1, 8, 8, 16]             256\n",
      "          Linear-523             [-1, 8, 8, 16]             256\n",
      "          Linear-524            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-525            [-1, 128, 8, 8]               0\n",
      "          Linear-526             [-1, 8, 8, 16]             256\n",
      "          Linear-527             [-1, 8, 8, 16]             256\n",
      "          Linear-528             [-1, 8, 8, 16]             256\n",
      "          Linear-529            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-530            [-1, 128, 8, 8]               0\n",
      "            ReLU-531            [-1, 128, 8, 8]               0\n",
      "          Conv2d-532            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-533            [-1, 256, 8, 8]             512\n",
      "            ReLU-534            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-535            [-1, 256, 8, 8]               0\n",
      "          Conv2d-536            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-537            [-1, 128, 8, 8]             256\n",
      "            ReLU-538            [-1, 128, 8, 8]               0\n",
      "          Linear-539             [-1, 8, 8, 16]             256\n",
      "          Linear-540             [-1, 8, 8, 16]             256\n",
      "          Linear-541             [-1, 8, 8, 16]             256\n",
      "          Linear-542            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-543            [-1, 128, 8, 8]               0\n",
      "          Linear-544             [-1, 8, 8, 16]             256\n",
      "          Linear-545             [-1, 8, 8, 16]             256\n",
      "          Linear-546             [-1, 8, 8, 16]             256\n",
      "          Linear-547            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-548            [-1, 128, 8, 8]               0\n",
      "            ReLU-549            [-1, 128, 8, 8]               0\n",
      "          Conv2d-550            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-551            [-1, 256, 8, 8]             512\n",
      "            ReLU-552            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-553            [-1, 256, 8, 8]               0\n",
      "          Conv2d-554            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-555            [-1, 128, 8, 8]             256\n",
      "            ReLU-556            [-1, 128, 8, 8]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Linear-557             [-1, 8, 8, 16]             256\n",
      "          Linear-558             [-1, 8, 8, 16]             256\n",
      "          Linear-559             [-1, 8, 8, 16]             256\n",
      "          Linear-560            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-561            [-1, 128, 8, 8]               0\n",
      "          Linear-562             [-1, 8, 8, 16]             256\n",
      "          Linear-563             [-1, 8, 8, 16]             256\n",
      "          Linear-564             [-1, 8, 8, 16]             256\n",
      "          Linear-565            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-566            [-1, 128, 8, 8]               0\n",
      "            ReLU-567            [-1, 128, 8, 8]               0\n",
      "          Conv2d-568            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-569            [-1, 256, 8, 8]             512\n",
      "            ReLU-570            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-571            [-1, 256, 8, 8]               0\n",
      "          Conv2d-572            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-573            [-1, 128, 8, 8]             256\n",
      "            ReLU-574            [-1, 128, 8, 8]               0\n",
      "          Linear-575             [-1, 8, 8, 16]             256\n",
      "          Linear-576             [-1, 8, 8, 16]             256\n",
      "          Linear-577             [-1, 8, 8, 16]             256\n",
      "          Linear-578            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-579            [-1, 128, 8, 8]               0\n",
      "          Linear-580             [-1, 8, 8, 16]             256\n",
      "          Linear-581             [-1, 8, 8, 16]             256\n",
      "          Linear-582             [-1, 8, 8, 16]             256\n",
      "          Linear-583            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-584            [-1, 128, 8, 8]               0\n",
      "            ReLU-585            [-1, 128, 8, 8]               0\n",
      "          Conv2d-586            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-587            [-1, 256, 8, 8]             512\n",
      "            ReLU-588            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-589            [-1, 256, 8, 8]               0\n",
      "         Encoder-590            [-1, 256, 8, 8]               0\n",
      "          Conv2d-591            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-592            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-593            [-1, 128, 8, 8]             256\n",
      "            ReLU-594            [-1, 128, 8, 8]               0\n",
      "          Linear-595             [-1, 8, 8, 16]             256\n",
      "          Linear-596             [-1, 8, 8, 16]             256\n",
      "          Linear-597             [-1, 8, 8, 16]             256\n",
      "          Linear-598            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-599            [-1, 128, 8, 8]               0\n",
      "          Linear-600             [-1, 8, 8, 16]             256\n",
      "          Linear-601             [-1, 8, 8, 16]             256\n",
      "          Linear-602             [-1, 8, 8, 16]             256\n",
      "          Linear-603            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-604            [-1, 128, 8, 8]               0\n",
      "            ReLU-605            [-1, 128, 8, 8]               0\n",
      "          Conv2d-606            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-607            [-1, 256, 8, 8]             512\n",
      "            ReLU-608            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-609            [-1, 256, 8, 8]               0\n",
      "          Conv2d-610            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-611            [-1, 128, 8, 8]             256\n",
      "            ReLU-612            [-1, 128, 8, 8]               0\n",
      "          Linear-613             [-1, 8, 8, 16]             256\n",
      "          Linear-614             [-1, 8, 8, 16]             256\n",
      "          Linear-615             [-1, 8, 8, 16]             256\n",
      "          Linear-616            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-617            [-1, 128, 8, 8]               0\n",
      "          Linear-618             [-1, 8, 8, 16]             256\n",
      "          Linear-619             [-1, 8, 8, 16]             256\n",
      "          Linear-620             [-1, 8, 8, 16]             256\n",
      "          Linear-621            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-622            [-1, 128, 8, 8]               0\n",
      "            ReLU-623            [-1, 128, 8, 8]               0\n",
      "          Conv2d-624            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-625            [-1, 256, 8, 8]             512\n",
      "            ReLU-626            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-627            [-1, 256, 8, 8]               0\n",
      "          Conv2d-628            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-629            [-1, 128, 8, 8]             256\n",
      "            ReLU-630            [-1, 128, 8, 8]               0\n",
      "          Linear-631             [-1, 8, 8, 16]             256\n",
      "          Linear-632             [-1, 8, 8, 16]             256\n",
      "          Linear-633             [-1, 8, 8, 16]             256\n",
      "          Linear-634            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-635            [-1, 128, 8, 8]               0\n",
      "          Linear-636             [-1, 8, 8, 16]             256\n",
      "          Linear-637             [-1, 8, 8, 16]             256\n",
      "          Linear-638             [-1, 8, 8, 16]             256\n",
      "          Linear-639            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-640            [-1, 128, 8, 8]               0\n",
      "            ReLU-641            [-1, 128, 8, 8]               0\n",
      "          Conv2d-642            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-643            [-1, 256, 8, 8]             512\n",
      "            ReLU-644            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-645            [-1, 256, 8, 8]               0\n",
      "          Conv2d-646            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-647            [-1, 128, 8, 8]             256\n",
      "            ReLU-648            [-1, 128, 8, 8]               0\n",
      "          Linear-649             [-1, 8, 8, 16]             256\n",
      "          Linear-650             [-1, 8, 8, 16]             256\n",
      "          Linear-651             [-1, 8, 8, 16]             256\n",
      "          Linear-652            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-653            [-1, 128, 8, 8]               0\n",
      "          Linear-654             [-1, 8, 8, 16]             256\n",
      "          Linear-655             [-1, 8, 8, 16]             256\n",
      "          Linear-656             [-1, 8, 8, 16]             256\n",
      "          Linear-657            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-658            [-1, 128, 8, 8]               0\n",
      "            ReLU-659            [-1, 128, 8, 8]               0\n",
      "          Conv2d-660            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-661            [-1, 256, 8, 8]             512\n",
      "            ReLU-662            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-663            [-1, 256, 8, 8]               0\n",
      "          Conv2d-664            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-665            [-1, 128, 8, 8]             256\n",
      "            ReLU-666            [-1, 128, 8, 8]               0\n",
      "          Linear-667             [-1, 8, 8, 16]             256\n",
      "          Linear-668             [-1, 8, 8, 16]             256\n",
      "          Linear-669             [-1, 8, 8, 16]             256\n",
      "          Linear-670            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-671            [-1, 128, 8, 8]               0\n",
      "          Linear-672             [-1, 8, 8, 16]             256\n",
      "          Linear-673             [-1, 8, 8, 16]             256\n",
      "          Linear-674             [-1, 8, 8, 16]             256\n",
      "          Linear-675            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-676            [-1, 128, 8, 8]               0\n",
      "            ReLU-677            [-1, 128, 8, 8]               0\n",
      "          Conv2d-678            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-679            [-1, 256, 8, 8]             512\n",
      "            ReLU-680            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-681            [-1, 256, 8, 8]               0\n",
      "         Encoder-682            [-1, 256, 8, 8]               0\n",
      "          Conv2d-683            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-684            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-685            [-1, 128, 8, 8]             256\n",
      "            ReLU-686            [-1, 128, 8, 8]               0\n",
      "          Linear-687             [-1, 8, 8, 16]             256\n",
      "          Linear-688             [-1, 8, 8, 16]             256\n",
      "          Linear-689             [-1, 8, 8, 16]             256\n",
      "          Linear-690            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-691            [-1, 128, 8, 8]               0\n",
      "          Linear-692             [-1, 8, 8, 16]             256\n",
      "          Linear-693             [-1, 8, 8, 16]             256\n",
      "          Linear-694             [-1, 8, 8, 16]             256\n",
      "          Linear-695            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-696            [-1, 128, 8, 8]               0\n",
      "            ReLU-697            [-1, 128, 8, 8]               0\n",
      "          Conv2d-698            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-699            [-1, 256, 8, 8]             512\n",
      "            ReLU-700            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-701            [-1, 256, 8, 8]               0\n",
      "          Conv2d-702            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-703            [-1, 128, 8, 8]             256\n",
      "            ReLU-704            [-1, 128, 8, 8]               0\n",
      "          Linear-705             [-1, 8, 8, 16]             256\n",
      "          Linear-706             [-1, 8, 8, 16]             256\n",
      "          Linear-707             [-1, 8, 8, 16]             256\n",
      "          Linear-708            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-709            [-1, 128, 8, 8]               0\n",
      "          Linear-710             [-1, 8, 8, 16]             256\n",
      "          Linear-711             [-1, 8, 8, 16]             256\n",
      "          Linear-712             [-1, 8, 8, 16]             256\n",
      "          Linear-713            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-714            [-1, 128, 8, 8]               0\n",
      "            ReLU-715            [-1, 128, 8, 8]               0\n",
      "          Conv2d-716            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-717            [-1, 256, 8, 8]             512\n",
      "            ReLU-718            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-719            [-1, 256, 8, 8]               0\n",
      "          Conv2d-720            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-721            [-1, 128, 8, 8]             256\n",
      "            ReLU-722            [-1, 128, 8, 8]               0\n",
      "          Linear-723             [-1, 8, 8, 16]             256\n",
      "          Linear-724             [-1, 8, 8, 16]             256\n",
      "          Linear-725             [-1, 8, 8, 16]             256\n",
      "          Linear-726            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-727            [-1, 128, 8, 8]               0\n",
      "          Linear-728             [-1, 8, 8, 16]             256\n",
      "          Linear-729             [-1, 8, 8, 16]             256\n",
      "          Linear-730             [-1, 8, 8, 16]             256\n",
      "          Linear-731            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-732            [-1, 128, 8, 8]               0\n",
      "            ReLU-733            [-1, 128, 8, 8]               0\n",
      "          Conv2d-734            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-735            [-1, 256, 8, 8]             512\n",
      "            ReLU-736            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-737            [-1, 256, 8, 8]               0\n",
      "          Conv2d-738            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-739            [-1, 128, 8, 8]             256\n",
      "            ReLU-740            [-1, 128, 8, 8]               0\n",
      "          Linear-741             [-1, 8, 8, 16]             256\n",
      "          Linear-742             [-1, 8, 8, 16]             256\n",
      "          Linear-743             [-1, 8, 8, 16]             256\n",
      "          Linear-744            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-745            [-1, 128, 8, 8]               0\n",
      "          Linear-746             [-1, 8, 8, 16]             256\n",
      "          Linear-747             [-1, 8, 8, 16]             256\n",
      "          Linear-748             [-1, 8, 8, 16]             256\n",
      "          Linear-749            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-750            [-1, 128, 8, 8]               0\n",
      "            ReLU-751            [-1, 128, 8, 8]               0\n",
      "          Conv2d-752            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-753            [-1, 256, 8, 8]             512\n",
      "            ReLU-754            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-755            [-1, 256, 8, 8]               0\n",
      "          Conv2d-756            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-757            [-1, 128, 8, 8]             256\n",
      "            ReLU-758            [-1, 128, 8, 8]               0\n",
      "          Linear-759             [-1, 8, 8, 16]             256\n",
      "          Linear-760             [-1, 8, 8, 16]             256\n",
      "          Linear-761             [-1, 8, 8, 16]             256\n",
      "          Linear-762            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-763            [-1, 128, 8, 8]               0\n",
      "          Linear-764             [-1, 8, 8, 16]             256\n",
      "          Linear-765             [-1, 8, 8, 16]             256\n",
      "          Linear-766             [-1, 8, 8, 16]             256\n",
      "          Linear-767            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-768            [-1, 128, 8, 8]               0\n",
      "            ReLU-769            [-1, 128, 8, 8]               0\n",
      "          Conv2d-770            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-771            [-1, 256, 8, 8]             512\n",
      "            ReLU-772            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-773            [-1, 256, 8, 8]               0\n",
      "         Encoder-774            [-1, 256, 8, 8]               0\n",
      "          Conv2d-775            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-776            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-777            [-1, 128, 8, 8]             256\n",
      "            ReLU-778            [-1, 128, 8, 8]               0\n",
      "          Linear-779             [-1, 8, 8, 16]             256\n",
      "          Linear-780             [-1, 8, 8, 16]             256\n",
      "          Linear-781             [-1, 8, 8, 16]             256\n",
      "          Linear-782            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-783            [-1, 128, 8, 8]               0\n",
      "          Linear-784             [-1, 8, 8, 16]             256\n",
      "          Linear-785             [-1, 8, 8, 16]             256\n",
      "          Linear-786             [-1, 8, 8, 16]             256\n",
      "          Linear-787            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-788            [-1, 128, 8, 8]               0\n",
      "            ReLU-789            [-1, 128, 8, 8]               0\n",
      "          Conv2d-790            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-791            [-1, 256, 8, 8]             512\n",
      "            ReLU-792            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-793            [-1, 256, 8, 8]               0\n",
      "          Conv2d-794            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-795            [-1, 128, 8, 8]             256\n",
      "            ReLU-796            [-1, 128, 8, 8]               0\n",
      "          Linear-797             [-1, 8, 8, 16]             256\n",
      "          Linear-798             [-1, 8, 8, 16]             256\n",
      "          Linear-799             [-1, 8, 8, 16]             256\n",
      "          Linear-800            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-801            [-1, 128, 8, 8]               0\n",
      "          Linear-802             [-1, 8, 8, 16]             256\n",
      "          Linear-803             [-1, 8, 8, 16]             256\n",
      "          Linear-804             [-1, 8, 8, 16]             256\n",
      "          Linear-805            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-806            [-1, 128, 8, 8]               0\n",
      "            ReLU-807            [-1, 128, 8, 8]               0\n",
      "          Conv2d-808            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-809            [-1, 256, 8, 8]             512\n",
      "            ReLU-810            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-811            [-1, 256, 8, 8]               0\n",
      "          Conv2d-812            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-813            [-1, 128, 8, 8]             256\n",
      "            ReLU-814            [-1, 128, 8, 8]               0\n",
      "          Linear-815             [-1, 8, 8, 16]             256\n",
      "          Linear-816             [-1, 8, 8, 16]             256\n",
      "          Linear-817             [-1, 8, 8, 16]             256\n",
      "          Linear-818            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-819            [-1, 128, 8, 8]               0\n",
      "          Linear-820             [-1, 8, 8, 16]             256\n",
      "          Linear-821             [-1, 8, 8, 16]             256\n",
      "          Linear-822             [-1, 8, 8, 16]             256\n",
      "          Linear-823            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-824            [-1, 128, 8, 8]               0\n",
      "            ReLU-825            [-1, 128, 8, 8]               0\n",
      "          Conv2d-826            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-827            [-1, 256, 8, 8]             512\n",
      "            ReLU-828            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-829            [-1, 256, 8, 8]               0\n",
      "          Conv2d-830            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-831            [-1, 128, 8, 8]             256\n",
      "            ReLU-832            [-1, 128, 8, 8]               0\n",
      "          Linear-833             [-1, 8, 8, 16]             256\n",
      "          Linear-834             [-1, 8, 8, 16]             256\n",
      "          Linear-835             [-1, 8, 8, 16]             256\n",
      "          Linear-836            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-837            [-1, 128, 8, 8]               0\n",
      "          Linear-838             [-1, 8, 8, 16]             256\n",
      "          Linear-839             [-1, 8, 8, 16]             256\n",
      "          Linear-840             [-1, 8, 8, 16]             256\n",
      "          Linear-841            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-842            [-1, 128, 8, 8]               0\n",
      "            ReLU-843            [-1, 128, 8, 8]               0\n",
      "          Conv2d-844            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-845            [-1, 256, 8, 8]             512\n",
      "            ReLU-846            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-847            [-1, 256, 8, 8]               0\n",
      "          Conv2d-848            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-849            [-1, 128, 8, 8]             256\n",
      "            ReLU-850            [-1, 128, 8, 8]               0\n",
      "          Linear-851             [-1, 8, 8, 16]             256\n",
      "          Linear-852             [-1, 8, 8, 16]             256\n",
      "          Linear-853             [-1, 8, 8, 16]             256\n",
      "          Linear-854            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-855            [-1, 128, 8, 8]               0\n",
      "          Linear-856             [-1, 8, 8, 16]             256\n",
      "          Linear-857             [-1, 8, 8, 16]             256\n",
      "          Linear-858             [-1, 8, 8, 16]             256\n",
      "          Linear-859            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-860            [-1, 128, 8, 8]               0\n",
      "            ReLU-861            [-1, 128, 8, 8]               0\n",
      "          Conv2d-862            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-863            [-1, 256, 8, 8]             512\n",
      "            ReLU-864            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-865            [-1, 256, 8, 8]               0\n",
      "         Encoder-866            [-1, 256, 8, 8]               0\n",
      "          Conv2d-867            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-868            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-869            [-1, 128, 8, 8]             256\n",
      "            ReLU-870            [-1, 128, 8, 8]               0\n",
      "          Linear-871             [-1, 8, 8, 16]             256\n",
      "          Linear-872             [-1, 8, 8, 16]             256\n",
      "          Linear-873             [-1, 8, 8, 16]             256\n",
      "          Linear-874            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-875            [-1, 128, 8, 8]               0\n",
      "          Linear-876             [-1, 8, 8, 16]             256\n",
      "          Linear-877             [-1, 8, 8, 16]             256\n",
      "          Linear-878             [-1, 8, 8, 16]             256\n",
      "          Linear-879            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-880            [-1, 128, 8, 8]               0\n",
      "            ReLU-881            [-1, 128, 8, 8]               0\n",
      "          Conv2d-882            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-883            [-1, 256, 8, 8]             512\n",
      "            ReLU-884            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-885            [-1, 256, 8, 8]               0\n",
      "          Conv2d-886            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-887            [-1, 128, 8, 8]             256\n",
      "            ReLU-888            [-1, 128, 8, 8]               0\n",
      "          Linear-889             [-1, 8, 8, 16]             256\n",
      "          Linear-890             [-1, 8, 8, 16]             256\n",
      "          Linear-891             [-1, 8, 8, 16]             256\n",
      "          Linear-892            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-893            [-1, 128, 8, 8]               0\n",
      "          Linear-894             [-1, 8, 8, 16]             256\n",
      "          Linear-895             [-1, 8, 8, 16]             256\n",
      "          Linear-896             [-1, 8, 8, 16]             256\n",
      "          Linear-897            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-898            [-1, 128, 8, 8]               0\n",
      "            ReLU-899            [-1, 128, 8, 8]               0\n",
      "          Conv2d-900            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-901            [-1, 256, 8, 8]             512\n",
      "            ReLU-902            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-903            [-1, 256, 8, 8]               0\n",
      "          Conv2d-904            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-905            [-1, 128, 8, 8]             256\n",
      "            ReLU-906            [-1, 128, 8, 8]               0\n",
      "          Linear-907             [-1, 8, 8, 16]             256\n",
      "          Linear-908             [-1, 8, 8, 16]             256\n",
      "          Linear-909             [-1, 8, 8, 16]             256\n",
      "          Linear-910            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-911            [-1, 128, 8, 8]               0\n",
      "          Linear-912             [-1, 8, 8, 16]             256\n",
      "          Linear-913             [-1, 8, 8, 16]             256\n",
      "          Linear-914             [-1, 8, 8, 16]             256\n",
      "          Linear-915            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-916            [-1, 128, 8, 8]               0\n",
      "            ReLU-917            [-1, 128, 8, 8]               0\n",
      "          Conv2d-918            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-919            [-1, 256, 8, 8]             512\n",
      "            ReLU-920            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-921            [-1, 256, 8, 8]               0\n",
      "          Conv2d-922            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-923            [-1, 128, 8, 8]             256\n",
      "            ReLU-924            [-1, 128, 8, 8]               0\n",
      "          Linear-925             [-1, 8, 8, 16]             256\n",
      "          Linear-926             [-1, 8, 8, 16]             256\n",
      "          Linear-927             [-1, 8, 8, 16]             256\n",
      "          Linear-928            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-929            [-1, 128, 8, 8]               0\n",
      "          Linear-930             [-1, 8, 8, 16]             256\n",
      "          Linear-931             [-1, 8, 8, 16]             256\n",
      "          Linear-932             [-1, 8, 8, 16]             256\n",
      "          Linear-933            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-934            [-1, 128, 8, 8]               0\n",
      "            ReLU-935            [-1, 128, 8, 8]               0\n",
      "          Conv2d-936            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-937            [-1, 256, 8, 8]             512\n",
      "            ReLU-938            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-939            [-1, 256, 8, 8]               0\n",
      "          Conv2d-940            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-941            [-1, 128, 8, 8]             256\n",
      "            ReLU-942            [-1, 128, 8, 8]               0\n",
      "          Linear-943             [-1, 8, 8, 16]             256\n",
      "          Linear-944             [-1, 8, 8, 16]             256\n",
      "          Linear-945             [-1, 8, 8, 16]             256\n",
      "          Linear-946            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-947            [-1, 128, 8, 8]               0\n",
      "          Linear-948             [-1, 8, 8, 16]             256\n",
      "          Linear-949             [-1, 8, 8, 16]             256\n",
      "          Linear-950             [-1, 8, 8, 16]             256\n",
      "          Linear-951            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-952            [-1, 128, 8, 8]               0\n",
      "            ReLU-953            [-1, 128, 8, 8]               0\n",
      "          Conv2d-954            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-955            [-1, 256, 8, 8]             512\n",
      "            ReLU-956            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-957            [-1, 256, 8, 8]               0\n",
      "         Encoder-958            [-1, 256, 8, 8]               0\n",
      "          Conv2d-959            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-960            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-961            [-1, 128, 8, 8]             256\n",
      "            ReLU-962            [-1, 128, 8, 8]               0\n",
      "          Linear-963             [-1, 8, 8, 16]             256\n",
      "          Linear-964             [-1, 8, 8, 16]             256\n",
      "          Linear-965             [-1, 8, 8, 16]             256\n",
      "          Linear-966            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-967            [-1, 128, 8, 8]               0\n",
      "          Linear-968             [-1, 8, 8, 16]             256\n",
      "          Linear-969             [-1, 8, 8, 16]             256\n",
      "          Linear-970             [-1, 8, 8, 16]             256\n",
      "          Linear-971            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-972            [-1, 128, 8, 8]               0\n",
      "            ReLU-973            [-1, 128, 8, 8]               0\n",
      "          Conv2d-974            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-975            [-1, 256, 8, 8]             512\n",
      "            ReLU-976            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-977            [-1, 256, 8, 8]               0\n",
      "          Conv2d-978            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-979            [-1, 128, 8, 8]             256\n",
      "            ReLU-980            [-1, 128, 8, 8]               0\n",
      "          Linear-981             [-1, 8, 8, 16]             256\n",
      "          Linear-982             [-1, 8, 8, 16]             256\n",
      "          Linear-983             [-1, 8, 8, 16]             256\n",
      "          Linear-984            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-985            [-1, 128, 8, 8]               0\n",
      "          Linear-986             [-1, 8, 8, 16]             256\n",
      "          Linear-987             [-1, 8, 8, 16]             256\n",
      "          Linear-988             [-1, 8, 8, 16]             256\n",
      "          Linear-989            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-990            [-1, 128, 8, 8]               0\n",
      "            ReLU-991            [-1, 128, 8, 8]               0\n",
      "          Conv2d-992            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-993            [-1, 256, 8, 8]             512\n",
      "            ReLU-994            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-995            [-1, 256, 8, 8]               0\n",
      "          Conv2d-996            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-997            [-1, 128, 8, 8]             256\n",
      "            ReLU-998            [-1, 128, 8, 8]               0\n",
      "          Linear-999             [-1, 8, 8, 16]             256\n",
      "         Linear-1000             [-1, 8, 8, 16]             256\n",
      "         Linear-1001             [-1, 8, 8, 16]             256\n",
      "         Linear-1002            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1003            [-1, 128, 8, 8]               0\n",
      "         Linear-1004             [-1, 8, 8, 16]             256\n",
      "         Linear-1005             [-1, 8, 8, 16]             256\n",
      "         Linear-1006             [-1, 8, 8, 16]             256\n",
      "         Linear-1007            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1008            [-1, 128, 8, 8]               0\n",
      "           ReLU-1009            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1010            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1011            [-1, 256, 8, 8]             512\n",
      "           ReLU-1012            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1013            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1014            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1015            [-1, 128, 8, 8]             256\n",
      "           ReLU-1016            [-1, 128, 8, 8]               0\n",
      "         Linear-1017             [-1, 8, 8, 16]             256\n",
      "         Linear-1018             [-1, 8, 8, 16]             256\n",
      "         Linear-1019             [-1, 8, 8, 16]             256\n",
      "         Linear-1020            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1021            [-1, 128, 8, 8]               0\n",
      "         Linear-1022             [-1, 8, 8, 16]             256\n",
      "         Linear-1023             [-1, 8, 8, 16]             256\n",
      "         Linear-1024             [-1, 8, 8, 16]             256\n",
      "         Linear-1025            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1026            [-1, 128, 8, 8]               0\n",
      "           ReLU-1027            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1028            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1029            [-1, 256, 8, 8]             512\n",
      "           ReLU-1030            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1031            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1032            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1033            [-1, 128, 8, 8]             256\n",
      "           ReLU-1034            [-1, 128, 8, 8]               0\n",
      "         Linear-1035             [-1, 8, 8, 16]             256\n",
      "         Linear-1036             [-1, 8, 8, 16]             256\n",
      "         Linear-1037             [-1, 8, 8, 16]             256\n",
      "         Linear-1038            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1039            [-1, 128, 8, 8]               0\n",
      "         Linear-1040             [-1, 8, 8, 16]             256\n",
      "         Linear-1041             [-1, 8, 8, 16]             256\n",
      "         Linear-1042             [-1, 8, 8, 16]             256\n",
      "         Linear-1043            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1044            [-1, 128, 8, 8]               0\n",
      "           ReLU-1045            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1046            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1047            [-1, 256, 8, 8]             512\n",
      "           ReLU-1048            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1049            [-1, 256, 8, 8]               0\n",
      "        Encoder-1050            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1051            [-1, 256, 8, 8]          37,888\n",
      "         Conv2d-1052            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1053            [-1, 128, 8, 8]             256\n",
      "           ReLU-1054            [-1, 128, 8, 8]               0\n",
      "         Linear-1055             [-1, 8, 8, 16]             256\n",
      "         Linear-1056             [-1, 8, 8, 16]             256\n",
      "         Linear-1057             [-1, 8, 8, 16]             256\n",
      "         Linear-1058            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1059            [-1, 128, 8, 8]               0\n",
      "         Linear-1060             [-1, 8, 8, 16]             256\n",
      "         Linear-1061             [-1, 8, 8, 16]             256\n",
      "         Linear-1062             [-1, 8, 8, 16]             256\n",
      "         Linear-1063            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1064            [-1, 128, 8, 8]               0\n",
      "           ReLU-1065            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1066            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1067            [-1, 256, 8, 8]             512\n",
      "           ReLU-1068            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1069            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1070            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1071            [-1, 128, 8, 8]             256\n",
      "           ReLU-1072            [-1, 128, 8, 8]               0\n",
      "         Linear-1073             [-1, 8, 8, 16]             256\n",
      "         Linear-1074             [-1, 8, 8, 16]             256\n",
      "         Linear-1075             [-1, 8, 8, 16]             256\n",
      "         Linear-1076            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1077            [-1, 128, 8, 8]               0\n",
      "         Linear-1078             [-1, 8, 8, 16]             256\n",
      "         Linear-1079             [-1, 8, 8, 16]             256\n",
      "         Linear-1080             [-1, 8, 8, 16]             256\n",
      "         Linear-1081            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1082            [-1, 128, 8, 8]               0\n",
      "           ReLU-1083            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1084            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1085            [-1, 256, 8, 8]             512\n",
      "           ReLU-1086            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1087            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1088            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1089            [-1, 128, 8, 8]             256\n",
      "           ReLU-1090            [-1, 128, 8, 8]               0\n",
      "         Linear-1091             [-1, 8, 8, 16]             256\n",
      "         Linear-1092             [-1, 8, 8, 16]             256\n",
      "         Linear-1093             [-1, 8, 8, 16]             256\n",
      "         Linear-1094            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1095            [-1, 128, 8, 8]               0\n",
      "         Linear-1096             [-1, 8, 8, 16]             256\n",
      "         Linear-1097             [-1, 8, 8, 16]             256\n",
      "         Linear-1098             [-1, 8, 8, 16]             256\n",
      "         Linear-1099            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1100            [-1, 128, 8, 8]               0\n",
      "           ReLU-1101            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1102            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1103            [-1, 256, 8, 8]             512\n",
      "           ReLU-1104            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1105            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1106            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1107            [-1, 128, 8, 8]             256\n",
      "           ReLU-1108            [-1, 128, 8, 8]               0\n",
      "         Linear-1109             [-1, 8, 8, 16]             256\n",
      "         Linear-1110             [-1, 8, 8, 16]             256\n",
      "         Linear-1111             [-1, 8, 8, 16]             256\n",
      "         Linear-1112            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1113            [-1, 128, 8, 8]               0\n",
      "         Linear-1114             [-1, 8, 8, 16]             256\n",
      "         Linear-1115             [-1, 8, 8, 16]             256\n",
      "         Linear-1116             [-1, 8, 8, 16]             256\n",
      "         Linear-1117            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1118            [-1, 128, 8, 8]               0\n",
      "           ReLU-1119            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1120            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1121            [-1, 256, 8, 8]             512\n",
      "           ReLU-1122            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1123            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1124            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1125            [-1, 128, 8, 8]             256\n",
      "           ReLU-1126            [-1, 128, 8, 8]               0\n",
      "         Linear-1127             [-1, 8, 8, 16]             256\n",
      "         Linear-1128             [-1, 8, 8, 16]             256\n",
      "         Linear-1129             [-1, 8, 8, 16]             256\n",
      "         Linear-1130            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1131            [-1, 128, 8, 8]               0\n",
      "         Linear-1132             [-1, 8, 8, 16]             256\n",
      "         Linear-1133             [-1, 8, 8, 16]             256\n",
      "         Linear-1134             [-1, 8, 8, 16]             256\n",
      "         Linear-1135            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1136            [-1, 128, 8, 8]               0\n",
      "           ReLU-1137            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1138            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1139            [-1, 256, 8, 8]             512\n",
      "           ReLU-1140            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1141            [-1, 256, 8, 8]               0\n",
      "        Encoder-1142            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1143            [-1, 256, 8, 8]          37,888\n",
      "         Conv2d-1144            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1145            [-1, 128, 8, 8]             256\n",
      "           ReLU-1146            [-1, 128, 8, 8]               0\n",
      "         Linear-1147             [-1, 8, 8, 16]             256\n",
      "         Linear-1148             [-1, 8, 8, 16]             256\n",
      "         Linear-1149             [-1, 8, 8, 16]             256\n",
      "         Linear-1150            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1151            [-1, 128, 8, 8]               0\n",
      "         Linear-1152             [-1, 8, 8, 16]             256\n",
      "         Linear-1153             [-1, 8, 8, 16]             256\n",
      "         Linear-1154             [-1, 8, 8, 16]             256\n",
      "         Linear-1155            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1156            [-1, 128, 8, 8]               0\n",
      "           ReLU-1157            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1158            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1159            [-1, 256, 8, 8]             512\n",
      "           ReLU-1160            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1161            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1162            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1163            [-1, 128, 8, 8]             256\n",
      "           ReLU-1164            [-1, 128, 8, 8]               0\n",
      "         Linear-1165             [-1, 8, 8, 16]             256\n",
      "         Linear-1166             [-1, 8, 8, 16]             256\n",
      "         Linear-1167             [-1, 8, 8, 16]             256\n",
      "         Linear-1168            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1169            [-1, 128, 8, 8]               0\n",
      "         Linear-1170             [-1, 8, 8, 16]             256\n",
      "         Linear-1171             [-1, 8, 8, 16]             256\n",
      "         Linear-1172             [-1, 8, 8, 16]             256\n",
      "         Linear-1173            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1174            [-1, 128, 8, 8]               0\n",
      "           ReLU-1175            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1176            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1177            [-1, 256, 8, 8]             512\n",
      "           ReLU-1178            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1179            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1180            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1181            [-1, 128, 8, 8]             256\n",
      "           ReLU-1182            [-1, 128, 8, 8]               0\n",
      "         Linear-1183             [-1, 8, 8, 16]             256\n",
      "         Linear-1184             [-1, 8, 8, 16]             256\n",
      "         Linear-1185             [-1, 8, 8, 16]             256\n",
      "         Linear-1186            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1187            [-1, 128, 8, 8]               0\n",
      "         Linear-1188             [-1, 8, 8, 16]             256\n",
      "         Linear-1189             [-1, 8, 8, 16]             256\n",
      "         Linear-1190             [-1, 8, 8, 16]             256\n",
      "         Linear-1191            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1192            [-1, 128, 8, 8]               0\n",
      "           ReLU-1193            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1194            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1195            [-1, 256, 8, 8]             512\n",
      "           ReLU-1196            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1197            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1198            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1199            [-1, 128, 8, 8]             256\n",
      "           ReLU-1200            [-1, 128, 8, 8]               0\n",
      "         Linear-1201             [-1, 8, 8, 16]             256\n",
      "         Linear-1202             [-1, 8, 8, 16]             256\n",
      "         Linear-1203             [-1, 8, 8, 16]             256\n",
      "         Linear-1204            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1205            [-1, 128, 8, 8]               0\n",
      "         Linear-1206             [-1, 8, 8, 16]             256\n",
      "         Linear-1207             [-1, 8, 8, 16]             256\n",
      "         Linear-1208             [-1, 8, 8, 16]             256\n",
      "         Linear-1209            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1210            [-1, 128, 8, 8]               0\n",
      "           ReLU-1211            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1212            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1213            [-1, 256, 8, 8]             512\n",
      "           ReLU-1214            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1215            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1216            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1217            [-1, 128, 8, 8]             256\n",
      "           ReLU-1218            [-1, 128, 8, 8]               0\n",
      "         Linear-1219             [-1, 8, 8, 16]             256\n",
      "         Linear-1220             [-1, 8, 8, 16]             256\n",
      "         Linear-1221             [-1, 8, 8, 16]             256\n",
      "         Linear-1222            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1223            [-1, 128, 8, 8]               0\n",
      "         Linear-1224             [-1, 8, 8, 16]             256\n",
      "         Linear-1225             [-1, 8, 8, 16]             256\n",
      "         Linear-1226             [-1, 8, 8, 16]             256\n",
      "         Linear-1227            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1228            [-1, 128, 8, 8]               0\n",
      "           ReLU-1229            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1230            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1231            [-1, 256, 8, 8]             512\n",
      "           ReLU-1232            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1233            [-1, 256, 8, 8]               0\n",
      "        Encoder-1234            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1235            [-1, 256, 8, 8]          37,888\n",
      "         Conv2d-1236            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1237            [-1, 128, 8, 8]             256\n",
      "           ReLU-1238            [-1, 128, 8, 8]               0\n",
      "         Linear-1239             [-1, 8, 8, 16]             256\n",
      "         Linear-1240             [-1, 8, 8, 16]             256\n",
      "         Linear-1241             [-1, 8, 8, 16]             256\n",
      "         Linear-1242            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1243            [-1, 128, 8, 8]               0\n",
      "         Linear-1244             [-1, 8, 8, 16]             256\n",
      "         Linear-1245             [-1, 8, 8, 16]             256\n",
      "         Linear-1246             [-1, 8, 8, 16]             256\n",
      "         Linear-1247            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1248            [-1, 128, 8, 8]               0\n",
      "           ReLU-1249            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1250            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1251            [-1, 256, 8, 8]             512\n",
      "           ReLU-1252            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1253            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1254            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1255            [-1, 128, 8, 8]             256\n",
      "           ReLU-1256            [-1, 128, 8, 8]               0\n",
      "         Linear-1257             [-1, 8, 8, 16]             256\n",
      "         Linear-1258             [-1, 8, 8, 16]             256\n",
      "         Linear-1259             [-1, 8, 8, 16]             256\n",
      "         Linear-1260            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1261            [-1, 128, 8, 8]               0\n",
      "         Linear-1262             [-1, 8, 8, 16]             256\n",
      "         Linear-1263             [-1, 8, 8, 16]             256\n",
      "         Linear-1264             [-1, 8, 8, 16]             256\n",
      "         Linear-1265            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1266            [-1, 128, 8, 8]               0\n",
      "           ReLU-1267            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1268            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1269            [-1, 256, 8, 8]             512\n",
      "           ReLU-1270            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1271            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1272            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1273            [-1, 128, 8, 8]             256\n",
      "           ReLU-1274            [-1, 128, 8, 8]               0\n",
      "         Linear-1275             [-1, 8, 8, 16]             256\n",
      "         Linear-1276             [-1, 8, 8, 16]             256\n",
      "         Linear-1277             [-1, 8, 8, 16]             256\n",
      "         Linear-1278            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1279            [-1, 128, 8, 8]               0\n",
      "         Linear-1280             [-1, 8, 8, 16]             256\n",
      "         Linear-1281             [-1, 8, 8, 16]             256\n",
      "         Linear-1282             [-1, 8, 8, 16]             256\n",
      "         Linear-1283            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1284            [-1, 128, 8, 8]               0\n",
      "           ReLU-1285            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1286            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1287            [-1, 256, 8, 8]             512\n",
      "           ReLU-1288            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1289            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1290            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1291            [-1, 128, 8, 8]             256\n",
      "           ReLU-1292            [-1, 128, 8, 8]               0\n",
      "         Linear-1293             [-1, 8, 8, 16]             256\n",
      "         Linear-1294             [-1, 8, 8, 16]             256\n",
      "         Linear-1295             [-1, 8, 8, 16]             256\n",
      "         Linear-1296            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1297            [-1, 128, 8, 8]               0\n",
      "         Linear-1298             [-1, 8, 8, 16]             256\n",
      "         Linear-1299             [-1, 8, 8, 16]             256\n",
      "         Linear-1300             [-1, 8, 8, 16]             256\n",
      "         Linear-1301            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1302            [-1, 128, 8, 8]               0\n",
      "           ReLU-1303            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1304            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1305            [-1, 256, 8, 8]             512\n",
      "           ReLU-1306            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1307            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1308            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1309            [-1, 128, 8, 8]             256\n",
      "           ReLU-1310            [-1, 128, 8, 8]               0\n",
      "         Linear-1311             [-1, 8, 8, 16]             256\n",
      "         Linear-1312             [-1, 8, 8, 16]             256\n",
      "         Linear-1313             [-1, 8, 8, 16]             256\n",
      "         Linear-1314            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1315            [-1, 128, 8, 8]               0\n",
      "         Linear-1316             [-1, 8, 8, 16]             256\n",
      "         Linear-1317             [-1, 8, 8, 16]             256\n",
      "         Linear-1318             [-1, 8, 8, 16]             256\n",
      "         Linear-1319            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1320            [-1, 128, 8, 8]               0\n",
      "           ReLU-1321            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1322            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1323            [-1, 256, 8, 8]             512\n",
      "           ReLU-1324            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1325            [-1, 256, 8, 8]               0\n",
      "        Encoder-1326            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1327            [-1, 256, 8, 8]          37,888\n",
      "         Conv2d-1328            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1329            [-1, 128, 8, 8]             256\n",
      "           ReLU-1330            [-1, 128, 8, 8]               0\n",
      "         Linear-1331             [-1, 8, 8, 16]             256\n",
      "         Linear-1332             [-1, 8, 8, 16]             256\n",
      "         Linear-1333             [-1, 8, 8, 16]             256\n",
      "         Linear-1334            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1335            [-1, 128, 8, 8]               0\n",
      "         Linear-1336             [-1, 8, 8, 16]             256\n",
      "         Linear-1337             [-1, 8, 8, 16]             256\n",
      "         Linear-1338             [-1, 8, 8, 16]             256\n",
      "         Linear-1339            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1340            [-1, 128, 8, 8]               0\n",
      "           ReLU-1341            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1342            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1343            [-1, 256, 8, 8]             512\n",
      "           ReLU-1344            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1345            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1346            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1347            [-1, 128, 8, 8]             256\n",
      "           ReLU-1348            [-1, 128, 8, 8]               0\n",
      "         Linear-1349             [-1, 8, 8, 16]             256\n",
      "         Linear-1350             [-1, 8, 8, 16]             256\n",
      "         Linear-1351             [-1, 8, 8, 16]             256\n",
      "         Linear-1352            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1353            [-1, 128, 8, 8]               0\n",
      "         Linear-1354             [-1, 8, 8, 16]             256\n",
      "         Linear-1355             [-1, 8, 8, 16]             256\n",
      "         Linear-1356             [-1, 8, 8, 16]             256\n",
      "         Linear-1357            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1358            [-1, 128, 8, 8]               0\n",
      "           ReLU-1359            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1360            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1361            [-1, 256, 8, 8]             512\n",
      "           ReLU-1362            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1363            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1364            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1365            [-1, 128, 8, 8]             256\n",
      "           ReLU-1366            [-1, 128, 8, 8]               0\n",
      "         Linear-1367             [-1, 8, 8, 16]             256\n",
      "         Linear-1368             [-1, 8, 8, 16]             256\n",
      "         Linear-1369             [-1, 8, 8, 16]             256\n",
      "         Linear-1370            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1371            [-1, 128, 8, 8]               0\n",
      "         Linear-1372             [-1, 8, 8, 16]             256\n",
      "         Linear-1373             [-1, 8, 8, 16]             256\n",
      "         Linear-1374             [-1, 8, 8, 16]             256\n",
      "         Linear-1375            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1376            [-1, 128, 8, 8]               0\n",
      "           ReLU-1377            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1378            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1379            [-1, 256, 8, 8]             512\n",
      "           ReLU-1380            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1381            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1382            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1383            [-1, 128, 8, 8]             256\n",
      "           ReLU-1384            [-1, 128, 8, 8]               0\n",
      "         Linear-1385             [-1, 8, 8, 16]             256\n",
      "         Linear-1386             [-1, 8, 8, 16]             256\n",
      "         Linear-1387             [-1, 8, 8, 16]             256\n",
      "         Linear-1388            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1389            [-1, 128, 8, 8]               0\n",
      "         Linear-1390             [-1, 8, 8, 16]             256\n",
      "         Linear-1391             [-1, 8, 8, 16]             256\n",
      "         Linear-1392             [-1, 8, 8, 16]             256\n",
      "         Linear-1393            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1394            [-1, 128, 8, 8]               0\n",
      "           ReLU-1395            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1396            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1397            [-1, 256, 8, 8]             512\n",
      "           ReLU-1398            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1399            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1400            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1401            [-1, 128, 8, 8]             256\n",
      "           ReLU-1402            [-1, 128, 8, 8]               0\n",
      "         Linear-1403             [-1, 8, 8, 16]             256\n",
      "         Linear-1404             [-1, 8, 8, 16]             256\n",
      "         Linear-1405             [-1, 8, 8, 16]             256\n",
      "         Linear-1406            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1407            [-1, 128, 8, 8]               0\n",
      "         Linear-1408             [-1, 8, 8, 16]             256\n",
      "         Linear-1409             [-1, 8, 8, 16]             256\n",
      "         Linear-1410             [-1, 8, 8, 16]             256\n",
      "         Linear-1411            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1412            [-1, 128, 8, 8]               0\n",
      "           ReLU-1413            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1414            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1415            [-1, 256, 8, 8]             512\n",
      "           ReLU-1416            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1417            [-1, 256, 8, 8]               0\n",
      "        Encoder-1418            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1419            [-1, 256, 8, 8]          37,888\n",
      "         Conv2d-1420            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1421            [-1, 128, 8, 8]             256\n",
      "           ReLU-1422            [-1, 128, 8, 8]               0\n",
      "         Linear-1423             [-1, 8, 8, 16]             256\n",
      "         Linear-1424             [-1, 8, 8, 16]             256\n",
      "         Linear-1425             [-1, 8, 8, 16]             256\n",
      "         Linear-1426            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1427            [-1, 128, 8, 8]               0\n",
      "         Linear-1428             [-1, 8, 8, 16]             256\n",
      "         Linear-1429             [-1, 8, 8, 16]             256\n",
      "         Linear-1430             [-1, 8, 8, 16]             256\n",
      "         Linear-1431            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1432            [-1, 128, 8, 8]               0\n",
      "           ReLU-1433            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1434            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1435            [-1, 256, 8, 8]             512\n",
      "           ReLU-1436            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1437            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1438            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1439            [-1, 128, 8, 8]             256\n",
      "           ReLU-1440            [-1, 128, 8, 8]               0\n",
      "         Linear-1441             [-1, 8, 8, 16]             256\n",
      "         Linear-1442             [-1, 8, 8, 16]             256\n",
      "         Linear-1443             [-1, 8, 8, 16]             256\n",
      "         Linear-1444            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1445            [-1, 128, 8, 8]               0\n",
      "         Linear-1446             [-1, 8, 8, 16]             256\n",
      "         Linear-1447             [-1, 8, 8, 16]             256\n",
      "         Linear-1448             [-1, 8, 8, 16]             256\n",
      "         Linear-1449            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1450            [-1, 128, 8, 8]               0\n",
      "           ReLU-1451            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1452            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1453            [-1, 256, 8, 8]             512\n",
      "           ReLU-1454            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1455            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1456            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1457            [-1, 128, 8, 8]             256\n",
      "           ReLU-1458            [-1, 128, 8, 8]               0\n",
      "         Linear-1459             [-1, 8, 8, 16]             256\n",
      "         Linear-1460             [-1, 8, 8, 16]             256\n",
      "         Linear-1461             [-1, 8, 8, 16]             256\n",
      "         Linear-1462            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1463            [-1, 128, 8, 8]               0\n",
      "         Linear-1464             [-1, 8, 8, 16]             256\n",
      "         Linear-1465             [-1, 8, 8, 16]             256\n",
      "         Linear-1466             [-1, 8, 8, 16]             256\n",
      "         Linear-1467            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1468            [-1, 128, 8, 8]               0\n",
      "           ReLU-1469            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1470            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1471            [-1, 256, 8, 8]             512\n",
      "           ReLU-1472            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1473            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1474            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1475            [-1, 128, 8, 8]             256\n",
      "           ReLU-1476            [-1, 128, 8, 8]               0\n",
      "         Linear-1477             [-1, 8, 8, 16]             256\n",
      "         Linear-1478             [-1, 8, 8, 16]             256\n",
      "         Linear-1479             [-1, 8, 8, 16]             256\n",
      "         Linear-1480            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1481            [-1, 128, 8, 8]               0\n",
      "         Linear-1482             [-1, 8, 8, 16]             256\n",
      "         Linear-1483             [-1, 8, 8, 16]             256\n",
      "         Linear-1484             [-1, 8, 8, 16]             256\n",
      "         Linear-1485            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1486            [-1, 128, 8, 8]               0\n",
      "           ReLU-1487            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1488            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1489            [-1, 256, 8, 8]             512\n",
      "           ReLU-1490            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1491            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1492            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1493            [-1, 128, 8, 8]             256\n",
      "           ReLU-1494            [-1, 128, 8, 8]               0\n",
      "         Linear-1495             [-1, 8, 8, 16]             256\n",
      "         Linear-1496             [-1, 8, 8, 16]             256\n",
      "         Linear-1497             [-1, 8, 8, 16]             256\n",
      "         Linear-1498            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1499            [-1, 128, 8, 8]               0\n",
      "         Linear-1500             [-1, 8, 8, 16]             256\n",
      "         Linear-1501             [-1, 8, 8, 16]             256\n",
      "         Linear-1502             [-1, 8, 8, 16]             256\n",
      "         Linear-1503            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1504            [-1, 128, 8, 8]               0\n",
      "           ReLU-1505            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1506            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1507            [-1, 256, 8, 8]             512\n",
      "           ReLU-1508            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1509            [-1, 256, 8, 8]               0\n",
      "        Encoder-1510            [-1, 256, 8, 8]               0\n",
      "AdaptiveAvgPool2d-1511            [-1, 256, 1, 1]               0\n",
      "         Linear-1512                   [-1, 10]           2,570\n",
      "        Decoder-1513                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 8,949,002\n",
      "Trainable params: 8,949,002\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 124.13\n",
      "Params size (MB): 34.14\n",
      "Estimated Total Size (MB): 158.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%run MedT-C.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969d5569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa58cc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " frog  ship   cat   cat\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bff1a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 256, 32, 32]          37,888\n",
      "            Conv2d-2          [-1, 128, 32, 32]          32,896\n",
      "       BatchNorm2d-3          [-1, 128, 32, 32]             256\n",
      "              ReLU-4          [-1, 128, 32, 32]               0\n",
      "            Linear-5            [-1, 32, 8, 16]             256\n",
      "            Linear-6            [-1, 32, 8, 16]             256\n",
      "            Linear-7            [-1, 32, 8, 16]             256\n",
      "            Linear-8          [-1, 32, 32, 128]          16,512\n",
      "    AxialAttention-9          [-1, 128, 32, 32]               0\n",
      "           Linear-10            [-1, 32, 8, 16]             256\n",
      "           Linear-11            [-1, 32, 8, 16]             256\n",
      "           Linear-12            [-1, 32, 8, 16]             256\n",
      "           Linear-13          [-1, 32, 32, 128]          16,512\n",
      "   AxialAttention-14          [-1, 128, 32, 32]               0\n",
      "             ReLU-15          [-1, 128, 32, 32]               0\n",
      "           Conv2d-16          [-1, 256, 32, 32]          33,024\n",
      "      BatchNorm2d-17          [-1, 256, 32, 32]             512\n",
      "             ReLU-18          [-1, 256, 32, 32]               0\n",
      "GatedAxialTransformerLayer-19          [-1, 256, 32, 32]               0\n",
      "           Conv2d-20          [-1, 128, 32, 32]          32,896\n",
      "      BatchNorm2d-21          [-1, 128, 32, 32]             256\n",
      "             ReLU-22          [-1, 128, 32, 32]               0\n",
      "           Linear-23            [-1, 32, 8, 16]             256\n",
      "           Linear-24            [-1, 32, 8, 16]             256\n",
      "           Linear-25            [-1, 32, 8, 16]             256\n",
      "           Linear-26          [-1, 32, 32, 128]          16,512\n",
      "   AxialAttention-27          [-1, 128, 32, 32]               0\n",
      "           Linear-28            [-1, 32, 8, 16]             256\n",
      "           Linear-29            [-1, 32, 8, 16]             256\n",
      "           Linear-30            [-1, 32, 8, 16]             256\n",
      "           Linear-31          [-1, 32, 32, 128]          16,512\n",
      "   AxialAttention-32          [-1, 128, 32, 32]               0\n",
      "             ReLU-33          [-1, 128, 32, 32]               0\n",
      "           Conv2d-34          [-1, 256, 32, 32]          33,024\n",
      "      BatchNorm2d-35          [-1, 256, 32, 32]             512\n",
      "             ReLU-36          [-1, 256, 32, 32]               0\n",
      "GatedAxialTransformerLayer-37          [-1, 256, 32, 32]               0\n",
      "          Encoder-38          [-1, 256, 32, 32]               0\n",
      "           Conv2d-39            [-1, 256, 8, 8]          37,888\n",
      "           Conv2d-40            [-1, 128, 8, 8]          32,896\n",
      "      BatchNorm2d-41            [-1, 128, 8, 8]             256\n",
      "             ReLU-42            [-1, 128, 8, 8]               0\n",
      "           Linear-43             [-1, 8, 8, 16]             256\n",
      "           Linear-44             [-1, 8, 8, 16]             256\n",
      "           Linear-45             [-1, 8, 8, 16]             256\n",
      "           Linear-46            [-1, 8, 8, 128]          16,512\n",
      "   AxialAttention-47            [-1, 128, 8, 8]               0\n",
      "           Linear-48             [-1, 8, 8, 16]             256\n",
      "           Linear-49             [-1, 8, 8, 16]             256\n",
      "           Linear-50             [-1, 8, 8, 16]             256\n",
      "           Linear-51            [-1, 8, 8, 128]          16,512\n",
      "   AxialAttention-52            [-1, 128, 8, 8]               0\n",
      "             ReLU-53            [-1, 128, 8, 8]               0\n",
      "           Conv2d-54            [-1, 256, 8, 8]          33,024\n",
      "      BatchNorm2d-55            [-1, 256, 8, 8]             512\n",
      "             ReLU-56            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-57            [-1, 256, 8, 8]               0\n",
      "           Conv2d-58            [-1, 128, 8, 8]          32,896\n",
      "      BatchNorm2d-59            [-1, 128, 8, 8]             256\n",
      "             ReLU-60            [-1, 128, 8, 8]               0\n",
      "           Linear-61             [-1, 8, 8, 16]             256\n",
      "           Linear-62             [-1, 8, 8, 16]             256\n",
      "           Linear-63             [-1, 8, 8, 16]             256\n",
      "           Linear-64            [-1, 8, 8, 128]          16,512\n",
      "   AxialAttention-65            [-1, 128, 8, 8]               0\n",
      "           Linear-66             [-1, 8, 8, 16]             256\n",
      "           Linear-67             [-1, 8, 8, 16]             256\n",
      "           Linear-68             [-1, 8, 8, 16]             256\n",
      "           Linear-69            [-1, 8, 8, 128]          16,512\n",
      "   AxialAttention-70            [-1, 128, 8, 8]               0\n",
      "             ReLU-71            [-1, 128, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]          33,024\n",
      "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
      "             ReLU-74            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-75            [-1, 256, 8, 8]               0\n",
      "           Conv2d-76            [-1, 128, 8, 8]          32,896\n",
      "      BatchNorm2d-77            [-1, 128, 8, 8]             256\n",
      "             ReLU-78            [-1, 128, 8, 8]               0\n",
      "           Linear-79             [-1, 8, 8, 16]             256\n",
      "           Linear-80             [-1, 8, 8, 16]             256\n",
      "           Linear-81             [-1, 8, 8, 16]             256\n",
      "           Linear-82            [-1, 8, 8, 128]          16,512\n",
      "   AxialAttention-83            [-1, 128, 8, 8]               0\n",
      "           Linear-84             [-1, 8, 8, 16]             256\n",
      "           Linear-85             [-1, 8, 8, 16]             256\n",
      "           Linear-86             [-1, 8, 8, 16]             256\n",
      "           Linear-87            [-1, 8, 8, 128]          16,512\n",
      "   AxialAttention-88            [-1, 128, 8, 8]               0\n",
      "             ReLU-89            [-1, 128, 8, 8]               0\n",
      "           Conv2d-90            [-1, 256, 8, 8]          33,024\n",
      "      BatchNorm2d-91            [-1, 256, 8, 8]             512\n",
      "             ReLU-92            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 128, 8, 8]          32,896\n",
      "      BatchNorm2d-95            [-1, 128, 8, 8]             256\n",
      "             ReLU-96            [-1, 128, 8, 8]               0\n",
      "           Linear-97             [-1, 8, 8, 16]             256\n",
      "           Linear-98             [-1, 8, 8, 16]             256\n",
      "           Linear-99             [-1, 8, 8, 16]             256\n",
      "          Linear-100            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-101            [-1, 128, 8, 8]               0\n",
      "          Linear-102             [-1, 8, 8, 16]             256\n",
      "          Linear-103             [-1, 8, 8, 16]             256\n",
      "          Linear-104             [-1, 8, 8, 16]             256\n",
      "          Linear-105            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-106            [-1, 128, 8, 8]               0\n",
      "            ReLU-107            [-1, 128, 8, 8]               0\n",
      "          Conv2d-108            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-109            [-1, 256, 8, 8]             512\n",
      "            ReLU-110            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-111            [-1, 256, 8, 8]               0\n",
      "          Conv2d-112            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-113            [-1, 128, 8, 8]             256\n",
      "            ReLU-114            [-1, 128, 8, 8]               0\n",
      "          Linear-115             [-1, 8, 8, 16]             256\n",
      "          Linear-116             [-1, 8, 8, 16]             256\n",
      "          Linear-117             [-1, 8, 8, 16]             256\n",
      "          Linear-118            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-119            [-1, 128, 8, 8]               0\n",
      "          Linear-120             [-1, 8, 8, 16]             256\n",
      "          Linear-121             [-1, 8, 8, 16]             256\n",
      "          Linear-122             [-1, 8, 8, 16]             256\n",
      "          Linear-123            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-124            [-1, 128, 8, 8]               0\n",
      "            ReLU-125            [-1, 128, 8, 8]               0\n",
      "          Conv2d-126            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-127            [-1, 256, 8, 8]             512\n",
      "            ReLU-128            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-129            [-1, 256, 8, 8]               0\n",
      "         Encoder-130            [-1, 256, 8, 8]               0\n",
      "          Conv2d-131            [-1, 256, 8, 8]          37,888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Conv2d-132            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-133            [-1, 128, 8, 8]             256\n",
      "            ReLU-134            [-1, 128, 8, 8]               0\n",
      "          Linear-135             [-1, 8, 8, 16]             256\n",
      "          Linear-136             [-1, 8, 8, 16]             256\n",
      "          Linear-137             [-1, 8, 8, 16]             256\n",
      "          Linear-138            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-139            [-1, 128, 8, 8]               0\n",
      "          Linear-140             [-1, 8, 8, 16]             256\n",
      "          Linear-141             [-1, 8, 8, 16]             256\n",
      "          Linear-142             [-1, 8, 8, 16]             256\n",
      "          Linear-143            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-144            [-1, 128, 8, 8]               0\n",
      "            ReLU-145            [-1, 128, 8, 8]               0\n",
      "          Conv2d-146            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-147            [-1, 256, 8, 8]             512\n",
      "            ReLU-148            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-149            [-1, 256, 8, 8]               0\n",
      "          Conv2d-150            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-151            [-1, 128, 8, 8]             256\n",
      "            ReLU-152            [-1, 128, 8, 8]               0\n",
      "          Linear-153             [-1, 8, 8, 16]             256\n",
      "          Linear-154             [-1, 8, 8, 16]             256\n",
      "          Linear-155             [-1, 8, 8, 16]             256\n",
      "          Linear-156            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-157            [-1, 128, 8, 8]               0\n",
      "          Linear-158             [-1, 8, 8, 16]             256\n",
      "          Linear-159             [-1, 8, 8, 16]             256\n",
      "          Linear-160             [-1, 8, 8, 16]             256\n",
      "          Linear-161            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-162            [-1, 128, 8, 8]               0\n",
      "            ReLU-163            [-1, 128, 8, 8]               0\n",
      "          Conv2d-164            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-165            [-1, 256, 8, 8]             512\n",
      "            ReLU-166            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-167            [-1, 256, 8, 8]               0\n",
      "          Conv2d-168            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-169            [-1, 128, 8, 8]             256\n",
      "            ReLU-170            [-1, 128, 8, 8]               0\n",
      "          Linear-171             [-1, 8, 8, 16]             256\n",
      "          Linear-172             [-1, 8, 8, 16]             256\n",
      "          Linear-173             [-1, 8, 8, 16]             256\n",
      "          Linear-174            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-175            [-1, 128, 8, 8]               0\n",
      "          Linear-176             [-1, 8, 8, 16]             256\n",
      "          Linear-177             [-1, 8, 8, 16]             256\n",
      "          Linear-178             [-1, 8, 8, 16]             256\n",
      "          Linear-179            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-180            [-1, 128, 8, 8]               0\n",
      "            ReLU-181            [-1, 128, 8, 8]               0\n",
      "          Conv2d-182            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-183            [-1, 256, 8, 8]             512\n",
      "            ReLU-184            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-185            [-1, 256, 8, 8]               0\n",
      "          Conv2d-186            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-187            [-1, 128, 8, 8]             256\n",
      "            ReLU-188            [-1, 128, 8, 8]               0\n",
      "          Linear-189             [-1, 8, 8, 16]             256\n",
      "          Linear-190             [-1, 8, 8, 16]             256\n",
      "          Linear-191             [-1, 8, 8, 16]             256\n",
      "          Linear-192            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-193            [-1, 128, 8, 8]               0\n",
      "          Linear-194             [-1, 8, 8, 16]             256\n",
      "          Linear-195             [-1, 8, 8, 16]             256\n",
      "          Linear-196             [-1, 8, 8, 16]             256\n",
      "          Linear-197            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-198            [-1, 128, 8, 8]               0\n",
      "            ReLU-199            [-1, 128, 8, 8]               0\n",
      "          Conv2d-200            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-201            [-1, 256, 8, 8]             512\n",
      "            ReLU-202            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-203            [-1, 256, 8, 8]               0\n",
      "          Conv2d-204            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-205            [-1, 128, 8, 8]             256\n",
      "            ReLU-206            [-1, 128, 8, 8]               0\n",
      "          Linear-207             [-1, 8, 8, 16]             256\n",
      "          Linear-208             [-1, 8, 8, 16]             256\n",
      "          Linear-209             [-1, 8, 8, 16]             256\n",
      "          Linear-210            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-211            [-1, 128, 8, 8]               0\n",
      "          Linear-212             [-1, 8, 8, 16]             256\n",
      "          Linear-213             [-1, 8, 8, 16]             256\n",
      "          Linear-214             [-1, 8, 8, 16]             256\n",
      "          Linear-215            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-216            [-1, 128, 8, 8]               0\n",
      "            ReLU-217            [-1, 128, 8, 8]               0\n",
      "          Conv2d-218            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-219            [-1, 256, 8, 8]             512\n",
      "            ReLU-220            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-221            [-1, 256, 8, 8]               0\n",
      "         Encoder-222            [-1, 256, 8, 8]               0\n",
      "          Conv2d-223            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-224            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-225            [-1, 128, 8, 8]             256\n",
      "            ReLU-226            [-1, 128, 8, 8]               0\n",
      "          Linear-227             [-1, 8, 8, 16]             256\n",
      "          Linear-228             [-1, 8, 8, 16]             256\n",
      "          Linear-229             [-1, 8, 8, 16]             256\n",
      "          Linear-230            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-231            [-1, 128, 8, 8]               0\n",
      "          Linear-232             [-1, 8, 8, 16]             256\n",
      "          Linear-233             [-1, 8, 8, 16]             256\n",
      "          Linear-234             [-1, 8, 8, 16]             256\n",
      "          Linear-235            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-236            [-1, 128, 8, 8]               0\n",
      "            ReLU-237            [-1, 128, 8, 8]               0\n",
      "          Conv2d-238            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-239            [-1, 256, 8, 8]             512\n",
      "            ReLU-240            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-241            [-1, 256, 8, 8]               0\n",
      "          Conv2d-242            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-243            [-1, 128, 8, 8]             256\n",
      "            ReLU-244            [-1, 128, 8, 8]               0\n",
      "          Linear-245             [-1, 8, 8, 16]             256\n",
      "          Linear-246             [-1, 8, 8, 16]             256\n",
      "          Linear-247             [-1, 8, 8, 16]             256\n",
      "          Linear-248            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-249            [-1, 128, 8, 8]               0\n",
      "          Linear-250             [-1, 8, 8, 16]             256\n",
      "          Linear-251             [-1, 8, 8, 16]             256\n",
      "          Linear-252             [-1, 8, 8, 16]             256\n",
      "          Linear-253            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-254            [-1, 128, 8, 8]               0\n",
      "            ReLU-255            [-1, 128, 8, 8]               0\n",
      "          Conv2d-256            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-257            [-1, 256, 8, 8]             512\n",
      "            ReLU-258            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-259            [-1, 256, 8, 8]               0\n",
      "          Conv2d-260            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-261            [-1, 128, 8, 8]             256\n",
      "            ReLU-262            [-1, 128, 8, 8]               0\n",
      "          Linear-263             [-1, 8, 8, 16]             256\n",
      "          Linear-264             [-1, 8, 8, 16]             256\n",
      "          Linear-265             [-1, 8, 8, 16]             256\n",
      "          Linear-266            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-267            [-1, 128, 8, 8]               0\n",
      "          Linear-268             [-1, 8, 8, 16]             256\n",
      "          Linear-269             [-1, 8, 8, 16]             256\n",
      "          Linear-270             [-1, 8, 8, 16]             256\n",
      "          Linear-271            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-272            [-1, 128, 8, 8]               0\n",
      "            ReLU-273            [-1, 128, 8, 8]               0\n",
      "          Conv2d-274            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-275            [-1, 256, 8, 8]             512\n",
      "            ReLU-276            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-277            [-1, 256, 8, 8]               0\n",
      "          Conv2d-278            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-279            [-1, 128, 8, 8]             256\n",
      "            ReLU-280            [-1, 128, 8, 8]               0\n",
      "          Linear-281             [-1, 8, 8, 16]             256\n",
      "          Linear-282             [-1, 8, 8, 16]             256\n",
      "          Linear-283             [-1, 8, 8, 16]             256\n",
      "          Linear-284            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-285            [-1, 128, 8, 8]               0\n",
      "          Linear-286             [-1, 8, 8, 16]             256\n",
      "          Linear-287             [-1, 8, 8, 16]             256\n",
      "          Linear-288             [-1, 8, 8, 16]             256\n",
      "          Linear-289            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-290            [-1, 128, 8, 8]               0\n",
      "            ReLU-291            [-1, 128, 8, 8]               0\n",
      "          Conv2d-292            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-293            [-1, 256, 8, 8]             512\n",
      "            ReLU-294            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-295            [-1, 256, 8, 8]               0\n",
      "          Conv2d-296            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-297            [-1, 128, 8, 8]             256\n",
      "            ReLU-298            [-1, 128, 8, 8]               0\n",
      "          Linear-299             [-1, 8, 8, 16]             256\n",
      "          Linear-300             [-1, 8, 8, 16]             256\n",
      "          Linear-301             [-1, 8, 8, 16]             256\n",
      "          Linear-302            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-303            [-1, 128, 8, 8]               0\n",
      "          Linear-304             [-1, 8, 8, 16]             256\n",
      "          Linear-305             [-1, 8, 8, 16]             256\n",
      "          Linear-306             [-1, 8, 8, 16]             256\n",
      "          Linear-307            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-308            [-1, 128, 8, 8]               0\n",
      "            ReLU-309            [-1, 128, 8, 8]               0\n",
      "          Conv2d-310            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-311            [-1, 256, 8, 8]             512\n",
      "            ReLU-312            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-313            [-1, 256, 8, 8]               0\n",
      "         Encoder-314            [-1, 256, 8, 8]               0\n",
      "          Conv2d-315            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-316            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-317            [-1, 128, 8, 8]             256\n",
      "            ReLU-318            [-1, 128, 8, 8]               0\n",
      "          Linear-319             [-1, 8, 8, 16]             256\n",
      "          Linear-320             [-1, 8, 8, 16]             256\n",
      "          Linear-321             [-1, 8, 8, 16]             256\n",
      "          Linear-322            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-323            [-1, 128, 8, 8]               0\n",
      "          Linear-324             [-1, 8, 8, 16]             256\n",
      "          Linear-325             [-1, 8, 8, 16]             256\n",
      "          Linear-326             [-1, 8, 8, 16]             256\n",
      "          Linear-327            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-328            [-1, 128, 8, 8]               0\n",
      "            ReLU-329            [-1, 128, 8, 8]               0\n",
      "          Conv2d-330            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-331            [-1, 256, 8, 8]             512\n",
      "            ReLU-332            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-333            [-1, 256, 8, 8]               0\n",
      "          Conv2d-334            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-335            [-1, 128, 8, 8]             256\n",
      "            ReLU-336            [-1, 128, 8, 8]               0\n",
      "          Linear-337             [-1, 8, 8, 16]             256\n",
      "          Linear-338             [-1, 8, 8, 16]             256\n",
      "          Linear-339             [-1, 8, 8, 16]             256\n",
      "          Linear-340            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-341            [-1, 128, 8, 8]               0\n",
      "          Linear-342             [-1, 8, 8, 16]             256\n",
      "          Linear-343             [-1, 8, 8, 16]             256\n",
      "          Linear-344             [-1, 8, 8, 16]             256\n",
      "          Linear-345            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-346            [-1, 128, 8, 8]               0\n",
      "            ReLU-347            [-1, 128, 8, 8]               0\n",
      "          Conv2d-348            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-349            [-1, 256, 8, 8]             512\n",
      "            ReLU-350            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-351            [-1, 256, 8, 8]               0\n",
      "          Conv2d-352            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-353            [-1, 128, 8, 8]             256\n",
      "            ReLU-354            [-1, 128, 8, 8]               0\n",
      "          Linear-355             [-1, 8, 8, 16]             256\n",
      "          Linear-356             [-1, 8, 8, 16]             256\n",
      "          Linear-357             [-1, 8, 8, 16]             256\n",
      "          Linear-358            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-359            [-1, 128, 8, 8]               0\n",
      "          Linear-360             [-1, 8, 8, 16]             256\n",
      "          Linear-361             [-1, 8, 8, 16]             256\n",
      "          Linear-362             [-1, 8, 8, 16]             256\n",
      "          Linear-363            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-364            [-1, 128, 8, 8]               0\n",
      "            ReLU-365            [-1, 128, 8, 8]               0\n",
      "          Conv2d-366            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-367            [-1, 256, 8, 8]             512\n",
      "            ReLU-368            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-369            [-1, 256, 8, 8]               0\n",
      "          Conv2d-370            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-371            [-1, 128, 8, 8]             256\n",
      "            ReLU-372            [-1, 128, 8, 8]               0\n",
      "          Linear-373             [-1, 8, 8, 16]             256\n",
      "          Linear-374             [-1, 8, 8, 16]             256\n",
      "          Linear-375             [-1, 8, 8, 16]             256\n",
      "          Linear-376            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-377            [-1, 128, 8, 8]               0\n",
      "          Linear-378             [-1, 8, 8, 16]             256\n",
      "          Linear-379             [-1, 8, 8, 16]             256\n",
      "          Linear-380             [-1, 8, 8, 16]             256\n",
      "          Linear-381            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-382            [-1, 128, 8, 8]               0\n",
      "            ReLU-383            [-1, 128, 8, 8]               0\n",
      "          Conv2d-384            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-385            [-1, 256, 8, 8]             512\n",
      "            ReLU-386            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-387            [-1, 256, 8, 8]               0\n",
      "          Conv2d-388            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-389            [-1, 128, 8, 8]             256\n",
      "            ReLU-390            [-1, 128, 8, 8]               0\n",
      "          Linear-391             [-1, 8, 8, 16]             256\n",
      "          Linear-392             [-1, 8, 8, 16]             256\n",
      "          Linear-393             [-1, 8, 8, 16]             256\n",
      "          Linear-394            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-395            [-1, 128, 8, 8]               0\n",
      "          Linear-396             [-1, 8, 8, 16]             256\n",
      "          Linear-397             [-1, 8, 8, 16]             256\n",
      "          Linear-398             [-1, 8, 8, 16]             256\n",
      "          Linear-399            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-400            [-1, 128, 8, 8]               0\n",
      "            ReLU-401            [-1, 128, 8, 8]               0\n",
      "          Conv2d-402            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-403            [-1, 256, 8, 8]             512\n",
      "            ReLU-404            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-405            [-1, 256, 8, 8]               0\n",
      "         Encoder-406            [-1, 256, 8, 8]               0\n",
      "          Conv2d-407            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-408            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-409            [-1, 128, 8, 8]             256\n",
      "            ReLU-410            [-1, 128, 8, 8]               0\n",
      "          Linear-411             [-1, 8, 8, 16]             256\n",
      "          Linear-412             [-1, 8, 8, 16]             256\n",
      "          Linear-413             [-1, 8, 8, 16]             256\n",
      "          Linear-414            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-415            [-1, 128, 8, 8]               0\n",
      "          Linear-416             [-1, 8, 8, 16]             256\n",
      "          Linear-417             [-1, 8, 8, 16]             256\n",
      "          Linear-418             [-1, 8, 8, 16]             256\n",
      "          Linear-419            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-420            [-1, 128, 8, 8]               0\n",
      "            ReLU-421            [-1, 128, 8, 8]               0\n",
      "          Conv2d-422            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-423            [-1, 256, 8, 8]             512\n",
      "            ReLU-424            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-425            [-1, 256, 8, 8]               0\n",
      "          Conv2d-426            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-427            [-1, 128, 8, 8]             256\n",
      "            ReLU-428            [-1, 128, 8, 8]               0\n",
      "          Linear-429             [-1, 8, 8, 16]             256\n",
      "          Linear-430             [-1, 8, 8, 16]             256\n",
      "          Linear-431             [-1, 8, 8, 16]             256\n",
      "          Linear-432            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-433            [-1, 128, 8, 8]               0\n",
      "          Linear-434             [-1, 8, 8, 16]             256\n",
      "          Linear-435             [-1, 8, 8, 16]             256\n",
      "          Linear-436             [-1, 8, 8, 16]             256\n",
      "          Linear-437            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-438            [-1, 128, 8, 8]               0\n",
      "            ReLU-439            [-1, 128, 8, 8]               0\n",
      "          Conv2d-440            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-441            [-1, 256, 8, 8]             512\n",
      "            ReLU-442            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-443            [-1, 256, 8, 8]               0\n",
      "          Conv2d-444            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-445            [-1, 128, 8, 8]             256\n",
      "            ReLU-446            [-1, 128, 8, 8]               0\n",
      "          Linear-447             [-1, 8, 8, 16]             256\n",
      "          Linear-448             [-1, 8, 8, 16]             256\n",
      "          Linear-449             [-1, 8, 8, 16]             256\n",
      "          Linear-450            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-451            [-1, 128, 8, 8]               0\n",
      "          Linear-452             [-1, 8, 8, 16]             256\n",
      "          Linear-453             [-1, 8, 8, 16]             256\n",
      "          Linear-454             [-1, 8, 8, 16]             256\n",
      "          Linear-455            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-456            [-1, 128, 8, 8]               0\n",
      "            ReLU-457            [-1, 128, 8, 8]               0\n",
      "          Conv2d-458            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-459            [-1, 256, 8, 8]             512\n",
      "            ReLU-460            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-461            [-1, 256, 8, 8]               0\n",
      "          Conv2d-462            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-463            [-1, 128, 8, 8]             256\n",
      "            ReLU-464            [-1, 128, 8, 8]               0\n",
      "          Linear-465             [-1, 8, 8, 16]             256\n",
      "          Linear-466             [-1, 8, 8, 16]             256\n",
      "          Linear-467             [-1, 8, 8, 16]             256\n",
      "          Linear-468            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-469            [-1, 128, 8, 8]               0\n",
      "          Linear-470             [-1, 8, 8, 16]             256\n",
      "          Linear-471             [-1, 8, 8, 16]             256\n",
      "          Linear-472             [-1, 8, 8, 16]             256\n",
      "          Linear-473            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-474            [-1, 128, 8, 8]               0\n",
      "            ReLU-475            [-1, 128, 8, 8]               0\n",
      "          Conv2d-476            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-477            [-1, 256, 8, 8]             512\n",
      "            ReLU-478            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-479            [-1, 256, 8, 8]               0\n",
      "          Conv2d-480            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-481            [-1, 128, 8, 8]             256\n",
      "            ReLU-482            [-1, 128, 8, 8]               0\n",
      "          Linear-483             [-1, 8, 8, 16]             256\n",
      "          Linear-484             [-1, 8, 8, 16]             256\n",
      "          Linear-485             [-1, 8, 8, 16]             256\n",
      "          Linear-486            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-487            [-1, 128, 8, 8]               0\n",
      "          Linear-488             [-1, 8, 8, 16]             256\n",
      "          Linear-489             [-1, 8, 8, 16]             256\n",
      "          Linear-490             [-1, 8, 8, 16]             256\n",
      "          Linear-491            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-492            [-1, 128, 8, 8]               0\n",
      "            ReLU-493            [-1, 128, 8, 8]               0\n",
      "          Conv2d-494            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-495            [-1, 256, 8, 8]             512\n",
      "            ReLU-496            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-497            [-1, 256, 8, 8]               0\n",
      "         Encoder-498            [-1, 256, 8, 8]               0\n",
      "          Conv2d-499            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-500            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-501            [-1, 128, 8, 8]             256\n",
      "            ReLU-502            [-1, 128, 8, 8]               0\n",
      "          Linear-503             [-1, 8, 8, 16]             256\n",
      "          Linear-504             [-1, 8, 8, 16]             256\n",
      "          Linear-505             [-1, 8, 8, 16]             256\n",
      "          Linear-506            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-507            [-1, 128, 8, 8]               0\n",
      "          Linear-508             [-1, 8, 8, 16]             256\n",
      "          Linear-509             [-1, 8, 8, 16]             256\n",
      "          Linear-510             [-1, 8, 8, 16]             256\n",
      "          Linear-511            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-512            [-1, 128, 8, 8]               0\n",
      "            ReLU-513            [-1, 128, 8, 8]               0\n",
      "          Conv2d-514            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-515            [-1, 256, 8, 8]             512\n",
      "            ReLU-516            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-517            [-1, 256, 8, 8]               0\n",
      "          Conv2d-518            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-519            [-1, 128, 8, 8]             256\n",
      "            ReLU-520            [-1, 128, 8, 8]               0\n",
      "          Linear-521             [-1, 8, 8, 16]             256\n",
      "          Linear-522             [-1, 8, 8, 16]             256\n",
      "          Linear-523             [-1, 8, 8, 16]             256\n",
      "          Linear-524            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-525            [-1, 128, 8, 8]               0\n",
      "          Linear-526             [-1, 8, 8, 16]             256\n",
      "          Linear-527             [-1, 8, 8, 16]             256\n",
      "          Linear-528             [-1, 8, 8, 16]             256\n",
      "          Linear-529            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-530            [-1, 128, 8, 8]               0\n",
      "            ReLU-531            [-1, 128, 8, 8]               0\n",
      "          Conv2d-532            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-533            [-1, 256, 8, 8]             512\n",
      "            ReLU-534            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-535            [-1, 256, 8, 8]               0\n",
      "          Conv2d-536            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-537            [-1, 128, 8, 8]             256\n",
      "            ReLU-538            [-1, 128, 8, 8]               0\n",
      "          Linear-539             [-1, 8, 8, 16]             256\n",
      "          Linear-540             [-1, 8, 8, 16]             256\n",
      "          Linear-541             [-1, 8, 8, 16]             256\n",
      "          Linear-542            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-543            [-1, 128, 8, 8]               0\n",
      "          Linear-544             [-1, 8, 8, 16]             256\n",
      "          Linear-545             [-1, 8, 8, 16]             256\n",
      "          Linear-546             [-1, 8, 8, 16]             256\n",
      "          Linear-547            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-548            [-1, 128, 8, 8]               0\n",
      "            ReLU-549            [-1, 128, 8, 8]               0\n",
      "          Conv2d-550            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-551            [-1, 256, 8, 8]             512\n",
      "            ReLU-552            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-553            [-1, 256, 8, 8]               0\n",
      "          Conv2d-554            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-555            [-1, 128, 8, 8]             256\n",
      "            ReLU-556            [-1, 128, 8, 8]               0\n",
      "          Linear-557             [-1, 8, 8, 16]             256\n",
      "          Linear-558             [-1, 8, 8, 16]             256\n",
      "          Linear-559             [-1, 8, 8, 16]             256\n",
      "          Linear-560            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-561            [-1, 128, 8, 8]               0\n",
      "          Linear-562             [-1, 8, 8, 16]             256\n",
      "          Linear-563             [-1, 8, 8, 16]             256\n",
      "          Linear-564             [-1, 8, 8, 16]             256\n",
      "          Linear-565            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-566            [-1, 128, 8, 8]               0\n",
      "            ReLU-567            [-1, 128, 8, 8]               0\n",
      "          Conv2d-568            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-569            [-1, 256, 8, 8]             512\n",
      "            ReLU-570            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-571            [-1, 256, 8, 8]               0\n",
      "          Conv2d-572            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-573            [-1, 128, 8, 8]             256\n",
      "            ReLU-574            [-1, 128, 8, 8]               0\n",
      "          Linear-575             [-1, 8, 8, 16]             256\n",
      "          Linear-576             [-1, 8, 8, 16]             256\n",
      "          Linear-577             [-1, 8, 8, 16]             256\n",
      "          Linear-578            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-579            [-1, 128, 8, 8]               0\n",
      "          Linear-580             [-1, 8, 8, 16]             256\n",
      "          Linear-581             [-1, 8, 8, 16]             256\n",
      "          Linear-582             [-1, 8, 8, 16]             256\n",
      "          Linear-583            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-584            [-1, 128, 8, 8]               0\n",
      "            ReLU-585            [-1, 128, 8, 8]               0\n",
      "          Conv2d-586            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-587            [-1, 256, 8, 8]             512\n",
      "            ReLU-588            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-589            [-1, 256, 8, 8]               0\n",
      "         Encoder-590            [-1, 256, 8, 8]               0\n",
      "          Conv2d-591            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-592            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-593            [-1, 128, 8, 8]             256\n",
      "            ReLU-594            [-1, 128, 8, 8]               0\n",
      "          Linear-595             [-1, 8, 8, 16]             256\n",
      "          Linear-596             [-1, 8, 8, 16]             256\n",
      "          Linear-597             [-1, 8, 8, 16]             256\n",
      "          Linear-598            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-599            [-1, 128, 8, 8]               0\n",
      "          Linear-600             [-1, 8, 8, 16]             256\n",
      "          Linear-601             [-1, 8, 8, 16]             256\n",
      "          Linear-602             [-1, 8, 8, 16]             256\n",
      "          Linear-603            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-604            [-1, 128, 8, 8]               0\n",
      "            ReLU-605            [-1, 128, 8, 8]               0\n",
      "          Conv2d-606            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-607            [-1, 256, 8, 8]             512\n",
      "            ReLU-608            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-609            [-1, 256, 8, 8]               0\n",
      "          Conv2d-610            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-611            [-1, 128, 8, 8]             256\n",
      "            ReLU-612            [-1, 128, 8, 8]               0\n",
      "          Linear-613             [-1, 8, 8, 16]             256\n",
      "          Linear-614             [-1, 8, 8, 16]             256\n",
      "          Linear-615             [-1, 8, 8, 16]             256\n",
      "          Linear-616            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-617            [-1, 128, 8, 8]               0\n",
      "          Linear-618             [-1, 8, 8, 16]             256\n",
      "          Linear-619             [-1, 8, 8, 16]             256\n",
      "          Linear-620             [-1, 8, 8, 16]             256\n",
      "          Linear-621            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-622            [-1, 128, 8, 8]               0\n",
      "            ReLU-623            [-1, 128, 8, 8]               0\n",
      "          Conv2d-624            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-625            [-1, 256, 8, 8]             512\n",
      "            ReLU-626            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-627            [-1, 256, 8, 8]               0\n",
      "          Conv2d-628            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-629            [-1, 128, 8, 8]             256\n",
      "            ReLU-630            [-1, 128, 8, 8]               0\n",
      "          Linear-631             [-1, 8, 8, 16]             256\n",
      "          Linear-632             [-1, 8, 8, 16]             256\n",
      "          Linear-633             [-1, 8, 8, 16]             256\n",
      "          Linear-634            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-635            [-1, 128, 8, 8]               0\n",
      "          Linear-636             [-1, 8, 8, 16]             256\n",
      "          Linear-637             [-1, 8, 8, 16]             256\n",
      "          Linear-638             [-1, 8, 8, 16]             256\n",
      "          Linear-639            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-640            [-1, 128, 8, 8]               0\n",
      "            ReLU-641            [-1, 128, 8, 8]               0\n",
      "          Conv2d-642            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-643            [-1, 256, 8, 8]             512\n",
      "            ReLU-644            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-645            [-1, 256, 8, 8]               0\n",
      "          Conv2d-646            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-647            [-1, 128, 8, 8]             256\n",
      "            ReLU-648            [-1, 128, 8, 8]               0\n",
      "          Linear-649             [-1, 8, 8, 16]             256\n",
      "          Linear-650             [-1, 8, 8, 16]             256\n",
      "          Linear-651             [-1, 8, 8, 16]             256\n",
      "          Linear-652            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-653            [-1, 128, 8, 8]               0\n",
      "          Linear-654             [-1, 8, 8, 16]             256\n",
      "          Linear-655             [-1, 8, 8, 16]             256\n",
      "          Linear-656             [-1, 8, 8, 16]             256\n",
      "          Linear-657            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-658            [-1, 128, 8, 8]               0\n",
      "            ReLU-659            [-1, 128, 8, 8]               0\n",
      "          Conv2d-660            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-661            [-1, 256, 8, 8]             512\n",
      "            ReLU-662            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-663            [-1, 256, 8, 8]               0\n",
      "          Conv2d-664            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-665            [-1, 128, 8, 8]             256\n",
      "            ReLU-666            [-1, 128, 8, 8]               0\n",
      "          Linear-667             [-1, 8, 8, 16]             256\n",
      "          Linear-668             [-1, 8, 8, 16]             256\n",
      "          Linear-669             [-1, 8, 8, 16]             256\n",
      "          Linear-670            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-671            [-1, 128, 8, 8]               0\n",
      "          Linear-672             [-1, 8, 8, 16]             256\n",
      "          Linear-673             [-1, 8, 8, 16]             256\n",
      "          Linear-674             [-1, 8, 8, 16]             256\n",
      "          Linear-675            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-676            [-1, 128, 8, 8]               0\n",
      "            ReLU-677            [-1, 128, 8, 8]               0\n",
      "          Conv2d-678            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-679            [-1, 256, 8, 8]             512\n",
      "            ReLU-680            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-681            [-1, 256, 8, 8]               0\n",
      "         Encoder-682            [-1, 256, 8, 8]               0\n",
      "          Conv2d-683            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-684            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-685            [-1, 128, 8, 8]             256\n",
      "            ReLU-686            [-1, 128, 8, 8]               0\n",
      "          Linear-687             [-1, 8, 8, 16]             256\n",
      "          Linear-688             [-1, 8, 8, 16]             256\n",
      "          Linear-689             [-1, 8, 8, 16]             256\n",
      "          Linear-690            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-691            [-1, 128, 8, 8]               0\n",
      "          Linear-692             [-1, 8, 8, 16]             256\n",
      "          Linear-693             [-1, 8, 8, 16]             256\n",
      "          Linear-694             [-1, 8, 8, 16]             256\n",
      "          Linear-695            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-696            [-1, 128, 8, 8]               0\n",
      "            ReLU-697            [-1, 128, 8, 8]               0\n",
      "          Conv2d-698            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-699            [-1, 256, 8, 8]             512\n",
      "            ReLU-700            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-701            [-1, 256, 8, 8]               0\n",
      "          Conv2d-702            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-703            [-1, 128, 8, 8]             256\n",
      "            ReLU-704            [-1, 128, 8, 8]               0\n",
      "          Linear-705             [-1, 8, 8, 16]             256\n",
      "          Linear-706             [-1, 8, 8, 16]             256\n",
      "          Linear-707             [-1, 8, 8, 16]             256\n",
      "          Linear-708            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-709            [-1, 128, 8, 8]               0\n",
      "          Linear-710             [-1, 8, 8, 16]             256\n",
      "          Linear-711             [-1, 8, 8, 16]             256\n",
      "          Linear-712             [-1, 8, 8, 16]             256\n",
      "          Linear-713            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-714            [-1, 128, 8, 8]               0\n",
      "            ReLU-715            [-1, 128, 8, 8]               0\n",
      "          Conv2d-716            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-717            [-1, 256, 8, 8]             512\n",
      "            ReLU-718            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-719            [-1, 256, 8, 8]               0\n",
      "          Conv2d-720            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-721            [-1, 128, 8, 8]             256\n",
      "            ReLU-722            [-1, 128, 8, 8]               0\n",
      "          Linear-723             [-1, 8, 8, 16]             256\n",
      "          Linear-724             [-1, 8, 8, 16]             256\n",
      "          Linear-725             [-1, 8, 8, 16]             256\n",
      "          Linear-726            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-727            [-1, 128, 8, 8]               0\n",
      "          Linear-728             [-1, 8, 8, 16]             256\n",
      "          Linear-729             [-1, 8, 8, 16]             256\n",
      "          Linear-730             [-1, 8, 8, 16]             256\n",
      "          Linear-731            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-732            [-1, 128, 8, 8]               0\n",
      "            ReLU-733            [-1, 128, 8, 8]               0\n",
      "          Conv2d-734            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-735            [-1, 256, 8, 8]             512\n",
      "            ReLU-736            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-737            [-1, 256, 8, 8]               0\n",
      "          Conv2d-738            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-739            [-1, 128, 8, 8]             256\n",
      "            ReLU-740            [-1, 128, 8, 8]               0\n",
      "          Linear-741             [-1, 8, 8, 16]             256\n",
      "          Linear-742             [-1, 8, 8, 16]             256\n",
      "          Linear-743             [-1, 8, 8, 16]             256\n",
      "          Linear-744            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-745            [-1, 128, 8, 8]               0\n",
      "          Linear-746             [-1, 8, 8, 16]             256\n",
      "          Linear-747             [-1, 8, 8, 16]             256\n",
      "          Linear-748             [-1, 8, 8, 16]             256\n",
      "          Linear-749            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-750            [-1, 128, 8, 8]               0\n",
      "            ReLU-751            [-1, 128, 8, 8]               0\n",
      "          Conv2d-752            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-753            [-1, 256, 8, 8]             512\n",
      "            ReLU-754            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-755            [-1, 256, 8, 8]               0\n",
      "          Conv2d-756            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-757            [-1, 128, 8, 8]             256\n",
      "            ReLU-758            [-1, 128, 8, 8]               0\n",
      "          Linear-759             [-1, 8, 8, 16]             256\n",
      "          Linear-760             [-1, 8, 8, 16]             256\n",
      "          Linear-761             [-1, 8, 8, 16]             256\n",
      "          Linear-762            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-763            [-1, 128, 8, 8]               0\n",
      "          Linear-764             [-1, 8, 8, 16]             256\n",
      "          Linear-765             [-1, 8, 8, 16]             256\n",
      "          Linear-766             [-1, 8, 8, 16]             256\n",
      "          Linear-767            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-768            [-1, 128, 8, 8]               0\n",
      "            ReLU-769            [-1, 128, 8, 8]               0\n",
      "          Conv2d-770            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-771            [-1, 256, 8, 8]             512\n",
      "            ReLU-772            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-773            [-1, 256, 8, 8]               0\n",
      "         Encoder-774            [-1, 256, 8, 8]               0\n",
      "          Conv2d-775            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-776            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-777            [-1, 128, 8, 8]             256\n",
      "            ReLU-778            [-1, 128, 8, 8]               0\n",
      "          Linear-779             [-1, 8, 8, 16]             256\n",
      "          Linear-780             [-1, 8, 8, 16]             256\n",
      "          Linear-781             [-1, 8, 8, 16]             256\n",
      "          Linear-782            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-783            [-1, 128, 8, 8]               0\n",
      "          Linear-784             [-1, 8, 8, 16]             256\n",
      "          Linear-785             [-1, 8, 8, 16]             256\n",
      "          Linear-786             [-1, 8, 8, 16]             256\n",
      "          Linear-787            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-788            [-1, 128, 8, 8]               0\n",
      "            ReLU-789            [-1, 128, 8, 8]               0\n",
      "          Conv2d-790            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-791            [-1, 256, 8, 8]             512\n",
      "            ReLU-792            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-793            [-1, 256, 8, 8]               0\n",
      "          Conv2d-794            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-795            [-1, 128, 8, 8]             256\n",
      "            ReLU-796            [-1, 128, 8, 8]               0\n",
      "          Linear-797             [-1, 8, 8, 16]             256\n",
      "          Linear-798             [-1, 8, 8, 16]             256\n",
      "          Linear-799             [-1, 8, 8, 16]             256\n",
      "          Linear-800            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-801            [-1, 128, 8, 8]               0\n",
      "          Linear-802             [-1, 8, 8, 16]             256\n",
      "          Linear-803             [-1, 8, 8, 16]             256\n",
      "          Linear-804             [-1, 8, 8, 16]             256\n",
      "          Linear-805            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-806            [-1, 128, 8, 8]               0\n",
      "            ReLU-807            [-1, 128, 8, 8]               0\n",
      "          Conv2d-808            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-809            [-1, 256, 8, 8]             512\n",
      "            ReLU-810            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-811            [-1, 256, 8, 8]               0\n",
      "          Conv2d-812            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-813            [-1, 128, 8, 8]             256\n",
      "            ReLU-814            [-1, 128, 8, 8]               0\n",
      "          Linear-815             [-1, 8, 8, 16]             256\n",
      "          Linear-816             [-1, 8, 8, 16]             256\n",
      "          Linear-817             [-1, 8, 8, 16]             256\n",
      "          Linear-818            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-819            [-1, 128, 8, 8]               0\n",
      "          Linear-820             [-1, 8, 8, 16]             256\n",
      "          Linear-821             [-1, 8, 8, 16]             256\n",
      "          Linear-822             [-1, 8, 8, 16]             256\n",
      "          Linear-823            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-824            [-1, 128, 8, 8]               0\n",
      "            ReLU-825            [-1, 128, 8, 8]               0\n",
      "          Conv2d-826            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-827            [-1, 256, 8, 8]             512\n",
      "            ReLU-828            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-829            [-1, 256, 8, 8]               0\n",
      "          Conv2d-830            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-831            [-1, 128, 8, 8]             256\n",
      "            ReLU-832            [-1, 128, 8, 8]               0\n",
      "          Linear-833             [-1, 8, 8, 16]             256\n",
      "          Linear-834             [-1, 8, 8, 16]             256\n",
      "          Linear-835             [-1, 8, 8, 16]             256\n",
      "          Linear-836            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-837            [-1, 128, 8, 8]               0\n",
      "          Linear-838             [-1, 8, 8, 16]             256\n",
      "          Linear-839             [-1, 8, 8, 16]             256\n",
      "          Linear-840             [-1, 8, 8, 16]             256\n",
      "          Linear-841            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-842            [-1, 128, 8, 8]               0\n",
      "            ReLU-843            [-1, 128, 8, 8]               0\n",
      "          Conv2d-844            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-845            [-1, 256, 8, 8]             512\n",
      "            ReLU-846            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-847            [-1, 256, 8, 8]               0\n",
      "          Conv2d-848            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-849            [-1, 128, 8, 8]             256\n",
      "            ReLU-850            [-1, 128, 8, 8]               0\n",
      "          Linear-851             [-1, 8, 8, 16]             256\n",
      "          Linear-852             [-1, 8, 8, 16]             256\n",
      "          Linear-853             [-1, 8, 8, 16]             256\n",
      "          Linear-854            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-855            [-1, 128, 8, 8]               0\n",
      "          Linear-856             [-1, 8, 8, 16]             256\n",
      "          Linear-857             [-1, 8, 8, 16]             256\n",
      "          Linear-858             [-1, 8, 8, 16]             256\n",
      "          Linear-859            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-860            [-1, 128, 8, 8]               0\n",
      "            ReLU-861            [-1, 128, 8, 8]               0\n",
      "          Conv2d-862            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-863            [-1, 256, 8, 8]             512\n",
      "            ReLU-864            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-865            [-1, 256, 8, 8]               0\n",
      "         Encoder-866            [-1, 256, 8, 8]               0\n",
      "          Conv2d-867            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-868            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-869            [-1, 128, 8, 8]             256\n",
      "            ReLU-870            [-1, 128, 8, 8]               0\n",
      "          Linear-871             [-1, 8, 8, 16]             256\n",
      "          Linear-872             [-1, 8, 8, 16]             256\n",
      "          Linear-873             [-1, 8, 8, 16]             256\n",
      "          Linear-874            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-875            [-1, 128, 8, 8]               0\n",
      "          Linear-876             [-1, 8, 8, 16]             256\n",
      "          Linear-877             [-1, 8, 8, 16]             256\n",
      "          Linear-878             [-1, 8, 8, 16]             256\n",
      "          Linear-879            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-880            [-1, 128, 8, 8]               0\n",
      "            ReLU-881            [-1, 128, 8, 8]               0\n",
      "          Conv2d-882            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-883            [-1, 256, 8, 8]             512\n",
      "            ReLU-884            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-885            [-1, 256, 8, 8]               0\n",
      "          Conv2d-886            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-887            [-1, 128, 8, 8]             256\n",
      "            ReLU-888            [-1, 128, 8, 8]               0\n",
      "          Linear-889             [-1, 8, 8, 16]             256\n",
      "          Linear-890             [-1, 8, 8, 16]             256\n",
      "          Linear-891             [-1, 8, 8, 16]             256\n",
      "          Linear-892            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-893            [-1, 128, 8, 8]               0\n",
      "          Linear-894             [-1, 8, 8, 16]             256\n",
      "          Linear-895             [-1, 8, 8, 16]             256\n",
      "          Linear-896             [-1, 8, 8, 16]             256\n",
      "          Linear-897            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-898            [-1, 128, 8, 8]               0\n",
      "            ReLU-899            [-1, 128, 8, 8]               0\n",
      "          Conv2d-900            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-901            [-1, 256, 8, 8]             512\n",
      "            ReLU-902            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-903            [-1, 256, 8, 8]               0\n",
      "          Conv2d-904            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-905            [-1, 128, 8, 8]             256\n",
      "            ReLU-906            [-1, 128, 8, 8]               0\n",
      "          Linear-907             [-1, 8, 8, 16]             256\n",
      "          Linear-908             [-1, 8, 8, 16]             256\n",
      "          Linear-909             [-1, 8, 8, 16]             256\n",
      "          Linear-910            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-911            [-1, 128, 8, 8]               0\n",
      "          Linear-912             [-1, 8, 8, 16]             256\n",
      "          Linear-913             [-1, 8, 8, 16]             256\n",
      "          Linear-914             [-1, 8, 8, 16]             256\n",
      "          Linear-915            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-916            [-1, 128, 8, 8]               0\n",
      "            ReLU-917            [-1, 128, 8, 8]               0\n",
      "          Conv2d-918            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-919            [-1, 256, 8, 8]             512\n",
      "            ReLU-920            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-921            [-1, 256, 8, 8]               0\n",
      "          Conv2d-922            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-923            [-1, 128, 8, 8]             256\n",
      "            ReLU-924            [-1, 128, 8, 8]               0\n",
      "          Linear-925             [-1, 8, 8, 16]             256\n",
      "          Linear-926             [-1, 8, 8, 16]             256\n",
      "          Linear-927             [-1, 8, 8, 16]             256\n",
      "          Linear-928            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-929            [-1, 128, 8, 8]               0\n",
      "          Linear-930             [-1, 8, 8, 16]             256\n",
      "          Linear-931             [-1, 8, 8, 16]             256\n",
      "          Linear-932             [-1, 8, 8, 16]             256\n",
      "          Linear-933            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-934            [-1, 128, 8, 8]               0\n",
      "            ReLU-935            [-1, 128, 8, 8]               0\n",
      "          Conv2d-936            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-937            [-1, 256, 8, 8]             512\n",
      "            ReLU-938            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-939            [-1, 256, 8, 8]               0\n",
      "          Conv2d-940            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-941            [-1, 128, 8, 8]             256\n",
      "            ReLU-942            [-1, 128, 8, 8]               0\n",
      "          Linear-943             [-1, 8, 8, 16]             256\n",
      "          Linear-944             [-1, 8, 8, 16]             256\n",
      "          Linear-945             [-1, 8, 8, 16]             256\n",
      "          Linear-946            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-947            [-1, 128, 8, 8]               0\n",
      "          Linear-948             [-1, 8, 8, 16]             256\n",
      "          Linear-949             [-1, 8, 8, 16]             256\n",
      "          Linear-950             [-1, 8, 8, 16]             256\n",
      "          Linear-951            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-952            [-1, 128, 8, 8]               0\n",
      "            ReLU-953            [-1, 128, 8, 8]               0\n",
      "          Conv2d-954            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-955            [-1, 256, 8, 8]             512\n",
      "            ReLU-956            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-957            [-1, 256, 8, 8]               0\n",
      "         Encoder-958            [-1, 256, 8, 8]               0\n",
      "          Conv2d-959            [-1, 256, 8, 8]          37,888\n",
      "          Conv2d-960            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-961            [-1, 128, 8, 8]             256\n",
      "            ReLU-962            [-1, 128, 8, 8]               0\n",
      "          Linear-963             [-1, 8, 8, 16]             256\n",
      "          Linear-964             [-1, 8, 8, 16]             256\n",
      "          Linear-965             [-1, 8, 8, 16]             256\n",
      "          Linear-966            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-967            [-1, 128, 8, 8]               0\n",
      "          Linear-968             [-1, 8, 8, 16]             256\n",
      "          Linear-969             [-1, 8, 8, 16]             256\n",
      "          Linear-970             [-1, 8, 8, 16]             256\n",
      "          Linear-971            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-972            [-1, 128, 8, 8]               0\n",
      "            ReLU-973            [-1, 128, 8, 8]               0\n",
      "          Conv2d-974            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-975            [-1, 256, 8, 8]             512\n",
      "            ReLU-976            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-977            [-1, 256, 8, 8]               0\n",
      "          Conv2d-978            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-979            [-1, 128, 8, 8]             256\n",
      "            ReLU-980            [-1, 128, 8, 8]               0\n",
      "          Linear-981             [-1, 8, 8, 16]             256\n",
      "          Linear-982             [-1, 8, 8, 16]             256\n",
      "          Linear-983             [-1, 8, 8, 16]             256\n",
      "          Linear-984            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-985            [-1, 128, 8, 8]               0\n",
      "          Linear-986             [-1, 8, 8, 16]             256\n",
      "          Linear-987             [-1, 8, 8, 16]             256\n",
      "          Linear-988             [-1, 8, 8, 16]             256\n",
      "          Linear-989            [-1, 8, 8, 128]          16,512\n",
      "  AxialAttention-990            [-1, 128, 8, 8]               0\n",
      "            ReLU-991            [-1, 128, 8, 8]               0\n",
      "          Conv2d-992            [-1, 256, 8, 8]          33,024\n",
      "     BatchNorm2d-993            [-1, 256, 8, 8]             512\n",
      "            ReLU-994            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-995            [-1, 256, 8, 8]               0\n",
      "          Conv2d-996            [-1, 128, 8, 8]          32,896\n",
      "     BatchNorm2d-997            [-1, 128, 8, 8]             256\n",
      "            ReLU-998            [-1, 128, 8, 8]               0\n",
      "          Linear-999             [-1, 8, 8, 16]             256\n",
      "         Linear-1000             [-1, 8, 8, 16]             256\n",
      "         Linear-1001             [-1, 8, 8, 16]             256\n",
      "         Linear-1002            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1003            [-1, 128, 8, 8]               0\n",
      "         Linear-1004             [-1, 8, 8, 16]             256\n",
      "         Linear-1005             [-1, 8, 8, 16]             256\n",
      "         Linear-1006             [-1, 8, 8, 16]             256\n",
      "         Linear-1007            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1008            [-1, 128, 8, 8]               0\n",
      "           ReLU-1009            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1010            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1011            [-1, 256, 8, 8]             512\n",
      "           ReLU-1012            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1013            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1014            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1015            [-1, 128, 8, 8]             256\n",
      "           ReLU-1016            [-1, 128, 8, 8]               0\n",
      "         Linear-1017             [-1, 8, 8, 16]             256\n",
      "         Linear-1018             [-1, 8, 8, 16]             256\n",
      "         Linear-1019             [-1, 8, 8, 16]             256\n",
      "         Linear-1020            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1021            [-1, 128, 8, 8]               0\n",
      "         Linear-1022             [-1, 8, 8, 16]             256\n",
      "         Linear-1023             [-1, 8, 8, 16]             256\n",
      "         Linear-1024             [-1, 8, 8, 16]             256\n",
      "         Linear-1025            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1026            [-1, 128, 8, 8]               0\n",
      "           ReLU-1027            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1028            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1029            [-1, 256, 8, 8]             512\n",
      "           ReLU-1030            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1031            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1032            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1033            [-1, 128, 8, 8]             256\n",
      "           ReLU-1034            [-1, 128, 8, 8]               0\n",
      "         Linear-1035             [-1, 8, 8, 16]             256\n",
      "         Linear-1036             [-1, 8, 8, 16]             256\n",
      "         Linear-1037             [-1, 8, 8, 16]             256\n",
      "         Linear-1038            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1039            [-1, 128, 8, 8]               0\n",
      "         Linear-1040             [-1, 8, 8, 16]             256\n",
      "         Linear-1041             [-1, 8, 8, 16]             256\n",
      "         Linear-1042             [-1, 8, 8, 16]             256\n",
      "         Linear-1043            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1044            [-1, 128, 8, 8]               0\n",
      "           ReLU-1045            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1046            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1047            [-1, 256, 8, 8]             512\n",
      "           ReLU-1048            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1049            [-1, 256, 8, 8]               0\n",
      "        Encoder-1050            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1051            [-1, 256, 8, 8]          37,888\n",
      "         Conv2d-1052            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1053            [-1, 128, 8, 8]             256\n",
      "           ReLU-1054            [-1, 128, 8, 8]               0\n",
      "         Linear-1055             [-1, 8, 8, 16]             256\n",
      "         Linear-1056             [-1, 8, 8, 16]             256\n",
      "         Linear-1057             [-1, 8, 8, 16]             256\n",
      "         Linear-1058            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1059            [-1, 128, 8, 8]               0\n",
      "         Linear-1060             [-1, 8, 8, 16]             256\n",
      "         Linear-1061             [-1, 8, 8, 16]             256\n",
      "         Linear-1062             [-1, 8, 8, 16]             256\n",
      "         Linear-1063            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1064            [-1, 128, 8, 8]               0\n",
      "           ReLU-1065            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1066            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1067            [-1, 256, 8, 8]             512\n",
      "           ReLU-1068            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1069            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1070            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1071            [-1, 128, 8, 8]             256\n",
      "           ReLU-1072            [-1, 128, 8, 8]               0\n",
      "         Linear-1073             [-1, 8, 8, 16]             256\n",
      "         Linear-1074             [-1, 8, 8, 16]             256\n",
      "         Linear-1075             [-1, 8, 8, 16]             256\n",
      "         Linear-1076            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1077            [-1, 128, 8, 8]               0\n",
      "         Linear-1078             [-1, 8, 8, 16]             256\n",
      "         Linear-1079             [-1, 8, 8, 16]             256\n",
      "         Linear-1080             [-1, 8, 8, 16]             256\n",
      "         Linear-1081            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1082            [-1, 128, 8, 8]               0\n",
      "           ReLU-1083            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1084            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1085            [-1, 256, 8, 8]             512\n",
      "           ReLU-1086            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1087            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1088            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1089            [-1, 128, 8, 8]             256\n",
      "           ReLU-1090            [-1, 128, 8, 8]               0\n",
      "         Linear-1091             [-1, 8, 8, 16]             256\n",
      "         Linear-1092             [-1, 8, 8, 16]             256\n",
      "         Linear-1093             [-1, 8, 8, 16]             256\n",
      "         Linear-1094            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1095            [-1, 128, 8, 8]               0\n",
      "         Linear-1096             [-1, 8, 8, 16]             256\n",
      "         Linear-1097             [-1, 8, 8, 16]             256\n",
      "         Linear-1098             [-1, 8, 8, 16]             256\n",
      "         Linear-1099            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1100            [-1, 128, 8, 8]               0\n",
      "           ReLU-1101            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1102            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1103            [-1, 256, 8, 8]             512\n",
      "           ReLU-1104            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1105            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1106            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1107            [-1, 128, 8, 8]             256\n",
      "           ReLU-1108            [-1, 128, 8, 8]               0\n",
      "         Linear-1109             [-1, 8, 8, 16]             256\n",
      "         Linear-1110             [-1, 8, 8, 16]             256\n",
      "         Linear-1111             [-1, 8, 8, 16]             256\n",
      "         Linear-1112            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1113            [-1, 128, 8, 8]               0\n",
      "         Linear-1114             [-1, 8, 8, 16]             256\n",
      "         Linear-1115             [-1, 8, 8, 16]             256\n",
      "         Linear-1116             [-1, 8, 8, 16]             256\n",
      "         Linear-1117            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1118            [-1, 128, 8, 8]               0\n",
      "           ReLU-1119            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1120            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1121            [-1, 256, 8, 8]             512\n",
      "           ReLU-1122            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1123            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1124            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1125            [-1, 128, 8, 8]             256\n",
      "           ReLU-1126            [-1, 128, 8, 8]               0\n",
      "         Linear-1127             [-1, 8, 8, 16]             256\n",
      "         Linear-1128             [-1, 8, 8, 16]             256\n",
      "         Linear-1129             [-1, 8, 8, 16]             256\n",
      "         Linear-1130            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1131            [-1, 128, 8, 8]               0\n",
      "         Linear-1132             [-1, 8, 8, 16]             256\n",
      "         Linear-1133             [-1, 8, 8, 16]             256\n",
      "         Linear-1134             [-1, 8, 8, 16]             256\n",
      "         Linear-1135            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1136            [-1, 128, 8, 8]               0\n",
      "           ReLU-1137            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1138            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1139            [-1, 256, 8, 8]             512\n",
      "           ReLU-1140            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1141            [-1, 256, 8, 8]               0\n",
      "        Encoder-1142            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1143            [-1, 256, 8, 8]          37,888\n",
      "         Conv2d-1144            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1145            [-1, 128, 8, 8]             256\n",
      "           ReLU-1146            [-1, 128, 8, 8]               0\n",
      "         Linear-1147             [-1, 8, 8, 16]             256\n",
      "         Linear-1148             [-1, 8, 8, 16]             256\n",
      "         Linear-1149             [-1, 8, 8, 16]             256\n",
      "         Linear-1150            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1151            [-1, 128, 8, 8]               0\n",
      "         Linear-1152             [-1, 8, 8, 16]             256\n",
      "         Linear-1153             [-1, 8, 8, 16]             256\n",
      "         Linear-1154             [-1, 8, 8, 16]             256\n",
      "         Linear-1155            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1156            [-1, 128, 8, 8]               0\n",
      "           ReLU-1157            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1158            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1159            [-1, 256, 8, 8]             512\n",
      "           ReLU-1160            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1161            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1162            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1163            [-1, 128, 8, 8]             256\n",
      "           ReLU-1164            [-1, 128, 8, 8]               0\n",
      "         Linear-1165             [-1, 8, 8, 16]             256\n",
      "         Linear-1166             [-1, 8, 8, 16]             256\n",
      "         Linear-1167             [-1, 8, 8, 16]             256\n",
      "         Linear-1168            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1169            [-1, 128, 8, 8]               0\n",
      "         Linear-1170             [-1, 8, 8, 16]             256\n",
      "         Linear-1171             [-1, 8, 8, 16]             256\n",
      "         Linear-1172             [-1, 8, 8, 16]             256\n",
      "         Linear-1173            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1174            [-1, 128, 8, 8]               0\n",
      "           ReLU-1175            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1176            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1177            [-1, 256, 8, 8]             512\n",
      "           ReLU-1178            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1179            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1180            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1181            [-1, 128, 8, 8]             256\n",
      "           ReLU-1182            [-1, 128, 8, 8]               0\n",
      "         Linear-1183             [-1, 8, 8, 16]             256\n",
      "         Linear-1184             [-1, 8, 8, 16]             256\n",
      "         Linear-1185             [-1, 8, 8, 16]             256\n",
      "         Linear-1186            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1187            [-1, 128, 8, 8]               0\n",
      "         Linear-1188             [-1, 8, 8, 16]             256\n",
      "         Linear-1189             [-1, 8, 8, 16]             256\n",
      "         Linear-1190             [-1, 8, 8, 16]             256\n",
      "         Linear-1191            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1192            [-1, 128, 8, 8]               0\n",
      "           ReLU-1193            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1194            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1195            [-1, 256, 8, 8]             512\n",
      "           ReLU-1196            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1197            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1198            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1199            [-1, 128, 8, 8]             256\n",
      "           ReLU-1200            [-1, 128, 8, 8]               0\n",
      "         Linear-1201             [-1, 8, 8, 16]             256\n",
      "         Linear-1202             [-1, 8, 8, 16]             256\n",
      "         Linear-1203             [-1, 8, 8, 16]             256\n",
      "         Linear-1204            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1205            [-1, 128, 8, 8]               0\n",
      "         Linear-1206             [-1, 8, 8, 16]             256\n",
      "         Linear-1207             [-1, 8, 8, 16]             256\n",
      "         Linear-1208             [-1, 8, 8, 16]             256\n",
      "         Linear-1209            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1210            [-1, 128, 8, 8]               0\n",
      "           ReLU-1211            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1212            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1213            [-1, 256, 8, 8]             512\n",
      "           ReLU-1214            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1215            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1216            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1217            [-1, 128, 8, 8]             256\n",
      "           ReLU-1218            [-1, 128, 8, 8]               0\n",
      "         Linear-1219             [-1, 8, 8, 16]             256\n",
      "         Linear-1220             [-1, 8, 8, 16]             256\n",
      "         Linear-1221             [-1, 8, 8, 16]             256\n",
      "         Linear-1222            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1223            [-1, 128, 8, 8]               0\n",
      "         Linear-1224             [-1, 8, 8, 16]             256\n",
      "         Linear-1225             [-1, 8, 8, 16]             256\n",
      "         Linear-1226             [-1, 8, 8, 16]             256\n",
      "         Linear-1227            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1228            [-1, 128, 8, 8]               0\n",
      "           ReLU-1229            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1230            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1231            [-1, 256, 8, 8]             512\n",
      "           ReLU-1232            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1233            [-1, 256, 8, 8]               0\n",
      "        Encoder-1234            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1235            [-1, 256, 8, 8]          37,888\n",
      "         Conv2d-1236            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1237            [-1, 128, 8, 8]             256\n",
      "           ReLU-1238            [-1, 128, 8, 8]               0\n",
      "         Linear-1239             [-1, 8, 8, 16]             256\n",
      "         Linear-1240             [-1, 8, 8, 16]             256\n",
      "         Linear-1241             [-1, 8, 8, 16]             256\n",
      "         Linear-1242            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1243            [-1, 128, 8, 8]               0\n",
      "         Linear-1244             [-1, 8, 8, 16]             256\n",
      "         Linear-1245             [-1, 8, 8, 16]             256\n",
      "         Linear-1246             [-1, 8, 8, 16]             256\n",
      "         Linear-1247            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1248            [-1, 128, 8, 8]               0\n",
      "           ReLU-1249            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1250            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1251            [-1, 256, 8, 8]             512\n",
      "           ReLU-1252            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1253            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1254            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1255            [-1, 128, 8, 8]             256\n",
      "           ReLU-1256            [-1, 128, 8, 8]               0\n",
      "         Linear-1257             [-1, 8, 8, 16]             256\n",
      "         Linear-1258             [-1, 8, 8, 16]             256\n",
      "         Linear-1259             [-1, 8, 8, 16]             256\n",
      "         Linear-1260            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1261            [-1, 128, 8, 8]               0\n",
      "         Linear-1262             [-1, 8, 8, 16]             256\n",
      "         Linear-1263             [-1, 8, 8, 16]             256\n",
      "         Linear-1264             [-1, 8, 8, 16]             256\n",
      "         Linear-1265            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1266            [-1, 128, 8, 8]               0\n",
      "           ReLU-1267            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1268            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1269            [-1, 256, 8, 8]             512\n",
      "           ReLU-1270            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1271            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1272            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1273            [-1, 128, 8, 8]             256\n",
      "           ReLU-1274            [-1, 128, 8, 8]               0\n",
      "         Linear-1275             [-1, 8, 8, 16]             256\n",
      "         Linear-1276             [-1, 8, 8, 16]             256\n",
      "         Linear-1277             [-1, 8, 8, 16]             256\n",
      "         Linear-1278            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1279            [-1, 128, 8, 8]               0\n",
      "         Linear-1280             [-1, 8, 8, 16]             256\n",
      "         Linear-1281             [-1, 8, 8, 16]             256\n",
      "         Linear-1282             [-1, 8, 8, 16]             256\n",
      "         Linear-1283            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1284            [-1, 128, 8, 8]               0\n",
      "           ReLU-1285            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1286            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1287            [-1, 256, 8, 8]             512\n",
      "           ReLU-1288            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1289            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1290            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1291            [-1, 128, 8, 8]             256\n",
      "           ReLU-1292            [-1, 128, 8, 8]               0\n",
      "         Linear-1293             [-1, 8, 8, 16]             256\n",
      "         Linear-1294             [-1, 8, 8, 16]             256\n",
      "         Linear-1295             [-1, 8, 8, 16]             256\n",
      "         Linear-1296            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1297            [-1, 128, 8, 8]               0\n",
      "         Linear-1298             [-1, 8, 8, 16]             256\n",
      "         Linear-1299             [-1, 8, 8, 16]             256\n",
      "         Linear-1300             [-1, 8, 8, 16]             256\n",
      "         Linear-1301            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1302            [-1, 128, 8, 8]               0\n",
      "           ReLU-1303            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1304            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1305            [-1, 256, 8, 8]             512\n",
      "           ReLU-1306            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1307            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1308            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1309            [-1, 128, 8, 8]             256\n",
      "           ReLU-1310            [-1, 128, 8, 8]               0\n",
      "         Linear-1311             [-1, 8, 8, 16]             256\n",
      "         Linear-1312             [-1, 8, 8, 16]             256\n",
      "         Linear-1313             [-1, 8, 8, 16]             256\n",
      "         Linear-1314            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1315            [-1, 128, 8, 8]               0\n",
      "         Linear-1316             [-1, 8, 8, 16]             256\n",
      "         Linear-1317             [-1, 8, 8, 16]             256\n",
      "         Linear-1318             [-1, 8, 8, 16]             256\n",
      "         Linear-1319            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1320            [-1, 128, 8, 8]               0\n",
      "           ReLU-1321            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1322            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1323            [-1, 256, 8, 8]             512\n",
      "           ReLU-1324            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1325            [-1, 256, 8, 8]               0\n",
      "        Encoder-1326            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1327            [-1, 256, 8, 8]          37,888\n",
      "         Conv2d-1328            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1329            [-1, 128, 8, 8]             256\n",
      "           ReLU-1330            [-1, 128, 8, 8]               0\n",
      "         Linear-1331             [-1, 8, 8, 16]             256\n",
      "         Linear-1332             [-1, 8, 8, 16]             256\n",
      "         Linear-1333             [-1, 8, 8, 16]             256\n",
      "         Linear-1334            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1335            [-1, 128, 8, 8]               0\n",
      "         Linear-1336             [-1, 8, 8, 16]             256\n",
      "         Linear-1337             [-1, 8, 8, 16]             256\n",
      "         Linear-1338             [-1, 8, 8, 16]             256\n",
      "         Linear-1339            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1340            [-1, 128, 8, 8]               0\n",
      "           ReLU-1341            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1342            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1343            [-1, 256, 8, 8]             512\n",
      "           ReLU-1344            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1345            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1346            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1347            [-1, 128, 8, 8]             256\n",
      "           ReLU-1348            [-1, 128, 8, 8]               0\n",
      "         Linear-1349             [-1, 8, 8, 16]             256\n",
      "         Linear-1350             [-1, 8, 8, 16]             256\n",
      "         Linear-1351             [-1, 8, 8, 16]             256\n",
      "         Linear-1352            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1353            [-1, 128, 8, 8]               0\n",
      "         Linear-1354             [-1, 8, 8, 16]             256\n",
      "         Linear-1355             [-1, 8, 8, 16]             256\n",
      "         Linear-1356             [-1, 8, 8, 16]             256\n",
      "         Linear-1357            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1358            [-1, 128, 8, 8]               0\n",
      "           ReLU-1359            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1360            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1361            [-1, 256, 8, 8]             512\n",
      "           ReLU-1362            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1363            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1364            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1365            [-1, 128, 8, 8]             256\n",
      "           ReLU-1366            [-1, 128, 8, 8]               0\n",
      "         Linear-1367             [-1, 8, 8, 16]             256\n",
      "         Linear-1368             [-1, 8, 8, 16]             256\n",
      "         Linear-1369             [-1, 8, 8, 16]             256\n",
      "         Linear-1370            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1371            [-1, 128, 8, 8]               0\n",
      "         Linear-1372             [-1, 8, 8, 16]             256\n",
      "         Linear-1373             [-1, 8, 8, 16]             256\n",
      "         Linear-1374             [-1, 8, 8, 16]             256\n",
      "         Linear-1375            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1376            [-1, 128, 8, 8]               0\n",
      "           ReLU-1377            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1378            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1379            [-1, 256, 8, 8]             512\n",
      "           ReLU-1380            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1381            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1382            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1383            [-1, 128, 8, 8]             256\n",
      "           ReLU-1384            [-1, 128, 8, 8]               0\n",
      "         Linear-1385             [-1, 8, 8, 16]             256\n",
      "         Linear-1386             [-1, 8, 8, 16]             256\n",
      "         Linear-1387             [-1, 8, 8, 16]             256\n",
      "         Linear-1388            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1389            [-1, 128, 8, 8]               0\n",
      "         Linear-1390             [-1, 8, 8, 16]             256\n",
      "         Linear-1391             [-1, 8, 8, 16]             256\n",
      "         Linear-1392             [-1, 8, 8, 16]             256\n",
      "         Linear-1393            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1394            [-1, 128, 8, 8]               0\n",
      "           ReLU-1395            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1396            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1397            [-1, 256, 8, 8]             512\n",
      "           ReLU-1398            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1399            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1400            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1401            [-1, 128, 8, 8]             256\n",
      "           ReLU-1402            [-1, 128, 8, 8]               0\n",
      "         Linear-1403             [-1, 8, 8, 16]             256\n",
      "         Linear-1404             [-1, 8, 8, 16]             256\n",
      "         Linear-1405             [-1, 8, 8, 16]             256\n",
      "         Linear-1406            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1407            [-1, 128, 8, 8]               0\n",
      "         Linear-1408             [-1, 8, 8, 16]             256\n",
      "         Linear-1409             [-1, 8, 8, 16]             256\n",
      "         Linear-1410             [-1, 8, 8, 16]             256\n",
      "         Linear-1411            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1412            [-1, 128, 8, 8]               0\n",
      "           ReLU-1413            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1414            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1415            [-1, 256, 8, 8]             512\n",
      "           ReLU-1416            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1417            [-1, 256, 8, 8]               0\n",
      "        Encoder-1418            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1419            [-1, 256, 8, 8]          37,888\n",
      "         Conv2d-1420            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1421            [-1, 128, 8, 8]             256\n",
      "           ReLU-1422            [-1, 128, 8, 8]               0\n",
      "         Linear-1423             [-1, 8, 8, 16]             256\n",
      "         Linear-1424             [-1, 8, 8, 16]             256\n",
      "         Linear-1425             [-1, 8, 8, 16]             256\n",
      "         Linear-1426            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1427            [-1, 128, 8, 8]               0\n",
      "         Linear-1428             [-1, 8, 8, 16]             256\n",
      "         Linear-1429             [-1, 8, 8, 16]             256\n",
      "         Linear-1430             [-1, 8, 8, 16]             256\n",
      "         Linear-1431            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1432            [-1, 128, 8, 8]               0\n",
      "           ReLU-1433            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1434            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1435            [-1, 256, 8, 8]             512\n",
      "           ReLU-1436            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1437            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1438            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1439            [-1, 128, 8, 8]             256\n",
      "           ReLU-1440            [-1, 128, 8, 8]               0\n",
      "         Linear-1441             [-1, 8, 8, 16]             256\n",
      "         Linear-1442             [-1, 8, 8, 16]             256\n",
      "         Linear-1443             [-1, 8, 8, 16]             256\n",
      "         Linear-1444            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1445            [-1, 128, 8, 8]               0\n",
      "         Linear-1446             [-1, 8, 8, 16]             256\n",
      "         Linear-1447             [-1, 8, 8, 16]             256\n",
      "         Linear-1448             [-1, 8, 8, 16]             256\n",
      "         Linear-1449            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1450            [-1, 128, 8, 8]               0\n",
      "           ReLU-1451            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1452            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1453            [-1, 256, 8, 8]             512\n",
      "           ReLU-1454            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1455            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1456            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1457            [-1, 128, 8, 8]             256\n",
      "           ReLU-1458            [-1, 128, 8, 8]               0\n",
      "         Linear-1459             [-1, 8, 8, 16]             256\n",
      "         Linear-1460             [-1, 8, 8, 16]             256\n",
      "         Linear-1461             [-1, 8, 8, 16]             256\n",
      "         Linear-1462            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1463            [-1, 128, 8, 8]               0\n",
      "         Linear-1464             [-1, 8, 8, 16]             256\n",
      "         Linear-1465             [-1, 8, 8, 16]             256\n",
      "         Linear-1466             [-1, 8, 8, 16]             256\n",
      "         Linear-1467            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1468            [-1, 128, 8, 8]               0\n",
      "           ReLU-1469            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1470            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1471            [-1, 256, 8, 8]             512\n",
      "           ReLU-1472            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1473            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1474            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1475            [-1, 128, 8, 8]             256\n",
      "           ReLU-1476            [-1, 128, 8, 8]               0\n",
      "         Linear-1477             [-1, 8, 8, 16]             256\n",
      "         Linear-1478             [-1, 8, 8, 16]             256\n",
      "         Linear-1479             [-1, 8, 8, 16]             256\n",
      "         Linear-1480            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1481            [-1, 128, 8, 8]               0\n",
      "         Linear-1482             [-1, 8, 8, 16]             256\n",
      "         Linear-1483             [-1, 8, 8, 16]             256\n",
      "         Linear-1484             [-1, 8, 8, 16]             256\n",
      "         Linear-1485            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1486            [-1, 128, 8, 8]               0\n",
      "           ReLU-1487            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1488            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1489            [-1, 256, 8, 8]             512\n",
      "           ReLU-1490            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1491            [-1, 256, 8, 8]               0\n",
      "         Conv2d-1492            [-1, 128, 8, 8]          32,896\n",
      "    BatchNorm2d-1493            [-1, 128, 8, 8]             256\n",
      "           ReLU-1494            [-1, 128, 8, 8]               0\n",
      "         Linear-1495             [-1, 8, 8, 16]             256\n",
      "         Linear-1496             [-1, 8, 8, 16]             256\n",
      "         Linear-1497             [-1, 8, 8, 16]             256\n",
      "         Linear-1498            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1499            [-1, 128, 8, 8]               0\n",
      "         Linear-1500             [-1, 8, 8, 16]             256\n",
      "         Linear-1501             [-1, 8, 8, 16]             256\n",
      "         Linear-1502             [-1, 8, 8, 16]             256\n",
      "         Linear-1503            [-1, 8, 8, 128]          16,512\n",
      " AxialAttention-1504            [-1, 128, 8, 8]               0\n",
      "           ReLU-1505            [-1, 128, 8, 8]               0\n",
      "         Conv2d-1506            [-1, 256, 8, 8]          33,024\n",
      "    BatchNorm2d-1507            [-1, 256, 8, 8]             512\n",
      "           ReLU-1508            [-1, 256, 8, 8]               0\n",
      "GatedAxialTransformerLayer-1509            [-1, 256, 8, 8]               0\n",
      "        Encoder-1510            [-1, 256, 8, 8]               0\n",
      "AdaptiveAvgPool2d-1511            [-1, 256, 1, 1]               0\n",
      "         Linear-1512                   [-1, 10]           2,570\n",
      "        Decoder-1513                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 8,949,002\n",
      "Trainable params: 8,949,002\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 124.13\n",
      "Params size (MB): 34.14\n",
      "Estimated Total Size (MB): 158.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# model = resnet18(3, 10)\n",
    "model = MedT_C(\n",
    "    img_dim=32,\n",
    "    in_channels=3,\n",
    "    patch_dim=8,\n",
    "    num_classes=10,\n",
    "    feature_dim=256\n",
    ")\n",
    "summary(model.cuda(), (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8399825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ebf23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.580\n",
      "[1,  4000] loss: 2.226\n",
      "[1,  6000] loss: 2.106\n",
      "[1,  8000] loss: 2.077\n",
      "[1, 10000] loss: 2.031\n",
      "[1, 12000] loss: 1.979\n",
      "[2,  2000] loss: 1.933\n",
      "[2,  4000] loss: 1.905\n",
      "[2,  6000] loss: 1.881\n",
      "[2,  8000] loss: 1.879\n",
      "[2, 10000] loss: 1.825\n",
      "[2, 12000] loss: 1.829\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # move inputs and labels to gpu\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1212c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b96019c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "# images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84a3da24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = MedT_C(\n",
    "    img_dim=32,\n",
    "    in_channels=3,\n",
    "    patch_dim=8,\n",
    "    num_classes=10,\n",
    "    feature_dim=256\n",
    ")\n",
    "trained_model.load_state_dict(torch.load(PATH))\n",
    "trained_model.to(device)\n",
    "next(trained_model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb7def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.to(device)\n",
    "outputs = trained_model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d46b6287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    dog truck  ship plane\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea2e877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 35 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = trained_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e19f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
